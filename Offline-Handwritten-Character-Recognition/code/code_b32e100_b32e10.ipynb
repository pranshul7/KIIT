{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the train and test folders\n",
    "train_path = 'C:/A/code/VSC/python/test/cropped_DevanagariHandwrittenCharacterDataset/Train/'\n",
    "test_path = 'C:/A/code/VSC/python/test/cropped_DevanagariHandwrittenCharacterDataset/Test/'\n",
    "\n",
    "# Define a function to load and preprocess the images\n",
    "def load_images(path):\n",
    "    # Create empty lists to store the images and labels\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    # Loop through each folder (which represents a class) in the path\n",
    "    for folder in os.listdir(path):\n",
    "        # Get the path to the folder\n",
    "        folder_path = os.path.join(path, folder)\n",
    "        # Loop through each image in the folder\n",
    "        for file in os.listdir(folder_path):\n",
    "            # Get the path to the image file\n",
    "            img_path = os.path.join(folder_path, file)\n",
    "            # Load the image using OpenCV\n",
    "            img = cv2.imread(img_path)\n",
    "            # Convert the image to grayscale\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            # Normalize the pixel values of the images\n",
    "            img = img.astype('float32') / 255.0\n",
    "            # Append the image to the images list\n",
    "            images.append(img)\n",
    "            # Append the label to the labels list\n",
    "            labels.append(folder)\n",
    "\n",
    "    # Convert the images and labels lists to NumPy arrays\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    # Return the images and labels arrays\n",
    "    return images, labels\n",
    "\n",
    "# Load the train images and labels\n",
    "train_images, train_labels = load_images(train_path)\n",
    "\n",
    "# Load the test images and labels\n",
    "test_images, test_labels = load_images(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Convert the string labels to integer labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_int = label_encoder.fit_transform(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the integer labels to one-hot encoding\n",
    "train_labels_onehot = to_categorical(train_labels_int, num_classes=46)\n",
    "\n",
    "# Split the data into the five quadrants\n",
    "x_train_tl = train_images[:,:14,:14].reshape(-1, 14, 14, 1)\n",
    "x_train_tr = train_images[:,:14,14:].reshape(-1, 14, 14, 1)\n",
    "x_train_bl = train_images[:,14:,:14].reshape(-1, 14, 14, 1)\n",
    "x_train_br = train_images[:,14:,14:].reshape(-1, 14, 14, 1)\n",
    "x_train_c = train_images[:,7:21,7:21].reshape(-1, 14, 14, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 12, 12, 16)        160       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 6, 6, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 4, 4, 32)          4640      \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 2, 2, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               66048     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 46)                23598     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 94,446\n",
      "Trainable params: 94,446\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "2444/2444 [==============================] - 10s 4ms/step - loss: 3.0535 - accuracy: 0.1766\n",
      "Epoch 2/100\n",
      "2444/2444 [==============================] - 9s 4ms/step - loss: 2.1886 - accuracy: 0.3597\n",
      "Epoch 3/100\n",
      "2444/2444 [==============================] - 9s 4ms/step - loss: 1.9262 - accuracy: 0.4282\n",
      "Epoch 4/100\n",
      "2444/2444 [==============================] - 12s 5ms/step - loss: 1.7594 - accuracy: 0.4716\n",
      "Epoch 5/100\n",
      "2444/2444 [==============================] - 11s 4ms/step - loss: 1.6436 - accuracy: 0.5019\n",
      "Epoch 6/100\n",
      "2444/2444 [==============================] - 11s 5ms/step - loss: 1.5537 - accuracy: 0.5276\n",
      "Epoch 7/100\n",
      "2444/2444 [==============================] - 11s 5ms/step - loss: 1.4821 - accuracy: 0.5469\n",
      "Epoch 8/100\n",
      "2444/2444 [==============================] - 11s 5ms/step - loss: 1.4239 - accuracy: 0.5622\n",
      "Epoch 9/100\n",
      "2444/2444 [==============================] - 11s 4ms/step - loss: 1.3748 - accuracy: 0.5742\n",
      "Epoch 10/100\n",
      "2444/2444 [==============================] - 11s 5ms/step - loss: 1.3337 - accuracy: 0.5853\n",
      "Epoch 11/100\n",
      "2444/2444 [==============================] - 11s 5ms/step - loss: 1.2986 - accuracy: 0.5952\n",
      "Epoch 12/100\n",
      "2444/2444 [==============================] - 12s 5ms/step - loss: 1.2635 - accuracy: 0.6046\n",
      "Epoch 13/100\n",
      "2444/2444 [==============================] - 12s 5ms/step - loss: 1.2360 - accuracy: 0.6124\n",
      "Epoch 14/100\n",
      "2444/2444 [==============================] - 12s 5ms/step - loss: 1.2081 - accuracy: 0.6209\n",
      "Epoch 15/100\n",
      "2444/2444 [==============================] - 12s 5ms/step - loss: 1.1848 - accuracy: 0.6261\n",
      "Epoch 16/100\n",
      "2444/2444 [==============================] - 12s 5ms/step - loss: 1.1642 - accuracy: 0.6330\n",
      "Epoch 17/100\n",
      "2444/2444 [==============================] - 13s 5ms/step - loss: 1.1428 - accuracy: 0.6385\n",
      "Epoch 18/100\n",
      "2444/2444 [==============================] - 13s 5ms/step - loss: 1.1239 - accuracy: 0.6437\n",
      "Epoch 19/100\n",
      "2444/2444 [==============================] - 13s 5ms/step - loss: 1.1073 - accuracy: 0.6492\n",
      "Epoch 20/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 1.0902 - accuracy: 0.6530\n",
      "Epoch 21/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 1.0745 - accuracy: 0.6589\n",
      "Epoch 22/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0596 - accuracy: 0.6621\n",
      "Epoch 23/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0461 - accuracy: 0.6667\n",
      "Epoch 24/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0330 - accuracy: 0.6702\n",
      "Epoch 25/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0212 - accuracy: 0.6727\n",
      "Epoch 26/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0088 - accuracy: 0.6755\n",
      "Epoch 27/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9986 - accuracy: 0.6795\n",
      "Epoch 28/100\n",
      "2444/2444 [==============================] - 16s 7ms/step - loss: 0.9880 - accuracy: 0.6837\n",
      "Epoch 29/100\n",
      "2444/2444 [==============================] - 17s 7ms/step - loss: 0.9782 - accuracy: 0.6861\n",
      "Epoch 30/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9700 - accuracy: 0.6885\n",
      "Epoch 31/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9598 - accuracy: 0.6913\n",
      "Epoch 32/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9507 - accuracy: 0.6938\n",
      "Epoch 33/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.9421 - accuracy: 0.6943\n",
      "Epoch 34/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9331 - accuracy: 0.6989\n",
      "Epoch 35/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9272 - accuracy: 0.7006\n",
      "Epoch 36/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.9192 - accuracy: 0.7031\n",
      "Epoch 37/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9123 - accuracy: 0.7055\n",
      "Epoch 38/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9056 - accuracy: 0.7075\n",
      "Epoch 39/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8974 - accuracy: 0.7089\n",
      "Epoch 40/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8921 - accuracy: 0.7125\n",
      "Epoch 41/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8845 - accuracy: 0.7139\n",
      "Epoch 42/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8801 - accuracy: 0.7150\n",
      "Epoch 43/100\n",
      "2444/2444 [==============================] - 19s 8ms/step - loss: 0.8742 - accuracy: 0.7172\n",
      "Epoch 44/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8681 - accuracy: 0.7188\n",
      "Epoch 45/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8622 - accuracy: 0.7202\n",
      "Epoch 46/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8576 - accuracy: 0.7227\n",
      "Epoch 47/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8518 - accuracy: 0.7230\n",
      "Epoch 48/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8485 - accuracy: 0.7236\n",
      "Epoch 49/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8423 - accuracy: 0.7261\n",
      "Epoch 50/100\n",
      "2444/2444 [==============================] - 16s 6ms/step - loss: 0.8379 - accuracy: 0.7268\n",
      "Epoch 51/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8321 - accuracy: 0.7294\n",
      "Epoch 52/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8270 - accuracy: 0.7303\n",
      "Epoch 53/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8260 - accuracy: 0.7313\n",
      "Epoch 54/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8200 - accuracy: 0.7316\n",
      "Epoch 55/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8157 - accuracy: 0.7335\n",
      "Epoch 56/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8110 - accuracy: 0.7354\n",
      "Epoch 57/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8070 - accuracy: 0.7352\n",
      "Epoch 58/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8042 - accuracy: 0.7383\n",
      "Epoch 59/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8007 - accuracy: 0.7370\n",
      "Epoch 60/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7970 - accuracy: 0.7381\n",
      "Epoch 61/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7925 - accuracy: 0.7404\n",
      "Epoch 62/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7890 - accuracy: 0.7424\n",
      "Epoch 63/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7861 - accuracy: 0.7411\n",
      "Epoch 64/100\n",
      "2444/2444 [==============================] - 16s 6ms/step - loss: 0.7817 - accuracy: 0.7448\n",
      "Epoch 65/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7785 - accuracy: 0.7452\n",
      "Epoch 66/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7759 - accuracy: 0.7438\n",
      "Epoch 67/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7711 - accuracy: 0.7463\n",
      "Epoch 68/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7684 - accuracy: 0.7472\n",
      "Epoch 69/100\n",
      "2444/2444 [==============================] - 16s 6ms/step - loss: 0.7661 - accuracy: 0.7475\n",
      "Epoch 70/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7624 - accuracy: 0.7504\n",
      "Epoch 71/100\n",
      "2444/2444 [==============================] - 16s 6ms/step - loss: 0.7587 - accuracy: 0.7513\n",
      "Epoch 72/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7572 - accuracy: 0.7517\n",
      "Epoch 73/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7546 - accuracy: 0.7507\n",
      "Epoch 74/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7509 - accuracy: 0.7531\n",
      "Epoch 75/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7487 - accuracy: 0.7537\n",
      "Epoch 76/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7454 - accuracy: 0.7556\n",
      "Epoch 77/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7413 - accuracy: 0.7559\n",
      "Epoch 78/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7402 - accuracy: 0.7558\n",
      "Epoch 79/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7369 - accuracy: 0.7572\n",
      "Epoch 80/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7338 - accuracy: 0.7580\n",
      "Epoch 81/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7330 - accuracy: 0.7569\n",
      "Epoch 82/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7296 - accuracy: 0.7592\n",
      "Epoch 83/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7267 - accuracy: 0.7593\n",
      "Epoch 84/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7256 - accuracy: 0.7587\n",
      "Epoch 85/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7221 - accuracy: 0.7604\n",
      "Epoch 86/100\n",
      "2444/2444 [==============================] - 16s 7ms/step - loss: 0.7207 - accuracy: 0.7617\n",
      "Epoch 87/100\n",
      "2444/2444 [==============================] - 16s 6ms/step - loss: 0.7184 - accuracy: 0.7615\n",
      "Epoch 88/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7152 - accuracy: 0.7633\n",
      "Epoch 89/100\n",
      "2444/2444 [==============================] - 18s 7ms/step - loss: 0.7151 - accuracy: 0.7628\n",
      "Epoch 90/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7123 - accuracy: 0.7643\n",
      "Epoch 91/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7077 - accuracy: 0.7654\n",
      "Epoch 92/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7085 - accuracy: 0.7659\n",
      "Epoch 93/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7048 - accuracy: 0.7664\n",
      "Epoch 94/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7033 - accuracy: 0.7659\n",
      "Epoch 95/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7001 - accuracy: 0.7673\n",
      "Epoch 96/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7000 - accuracy: 0.7669\n",
      "Epoch 97/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.6969 - accuracy: 0.7673\n",
      "Epoch 98/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.6959 - accuracy: 0.7697\n",
      "Epoch 99/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.6936 - accuracy: 0.7699\n",
      "Epoch 100/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.6927 - accuracy: 0.7695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21ed1a00110>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CNN for top left quadrant\n",
    "\n",
    "# Define the input shape for each quadrant\n",
    "input_shape = (14, 14, 1)\n",
    "\n",
    "# Create a sequential model for the top left quadrant\n",
    "model_tl = Sequential()\n",
    "\n",
    "# Add a convolutional layer with 16 filters, 3x3 kernel size, and sigmoid activation\n",
    "model_tl.add(Conv2D(16, kernel_size=(3, 3), activation='sigmoid', input_shape=input_shape))\n",
    "\n",
    "# Add a max pooling layer with 2x2 pool size\n",
    "model_tl.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Add a convolutional layer with 32 filters, 3x3 kernel size, and sigmoid activation\n",
    "model_tl.add(Conv2D(32, kernel_size=(3, 3), activation='sigmoid'))\n",
    "\n",
    "# Add a max pooling layer with 2x2 pool size\n",
    "model_tl.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the output of the previous layer\n",
    "model_tl.add(Flatten())\n",
    "\n",
    "# Add a dense layer with 512 units and relu activation\n",
    "model_tl.add(Dense(512, activation='relu'))\n",
    "\n",
    "# Add the output layer with 46 units and softmax activation\n",
    "model_tl.add(Dense(46, activation='softmax'))\n",
    "\n",
    "# Compile the model with categorical crossentropy loss and Adam optimizer\n",
    "model_tl.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model_tl.summary()\n",
    "\n",
    "# Train the model on the top left quadrant dataset\n",
    "model_tl.fit(x_train_tl, train_labels_onehot, batch_size=32, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 12, 12, 16)        160       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 6, 6, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 4, 4, 32)          4640      \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 2, 2, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 512)               66048     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 46)                23598     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 94,446\n",
      "Trainable params: 94,446\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 3.2584 - accuracy: 0.1388\n",
      "Epoch 2/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 2.5331 - accuracy: 0.2816\n",
      "Epoch 3/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 2.2802 - accuracy: 0.3410\n",
      "Epoch 4/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 2.1092 - accuracy: 0.3858\n",
      "Epoch 5/100\n",
      "2444/2444 [==============================] - 16s 6ms/step - loss: 1.9830 - accuracy: 0.4169\n",
      "Epoch 6/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.8910 - accuracy: 0.4417\n",
      "Epoch 7/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.8146 - accuracy: 0.4613\n",
      "Epoch 8/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.7548 - accuracy: 0.4768\n",
      "Epoch 9/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.7072 - accuracy: 0.4885\n",
      "Epoch 10/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.6631 - accuracy: 0.5030\n",
      "Epoch 11/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.6231 - accuracy: 0.5125\n",
      "Epoch 12/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.5874 - accuracy: 0.5225\n",
      "Epoch 13/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.5576 - accuracy: 0.5297\n",
      "Epoch 14/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.5304 - accuracy: 0.5362\n",
      "Epoch 15/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.5041 - accuracy: 0.5452\n",
      "Epoch 16/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.4798 - accuracy: 0.5519\n",
      "Epoch 17/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.4576 - accuracy: 0.5571\n",
      "Epoch 18/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.4400 - accuracy: 0.5625\n",
      "Epoch 19/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.4202 - accuracy: 0.5668\n",
      "Epoch 20/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.4040 - accuracy: 0.5720\n",
      "Epoch 21/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.3874 - accuracy: 0.5779\n",
      "Epoch 22/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.3728 - accuracy: 0.5811\n",
      "Epoch 23/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.3587 - accuracy: 0.5842\n",
      "Epoch 24/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.3449 - accuracy: 0.5896\n",
      "Epoch 25/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.3326 - accuracy: 0.5919\n",
      "Epoch 26/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 1.3206 - accuracy: 0.5950\n",
      "Epoch 27/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.3078 - accuracy: 0.5995\n",
      "Epoch 28/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.2967 - accuracy: 0.6028\n",
      "Epoch 29/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.2868 - accuracy: 0.6061\n",
      "Epoch 30/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.2773 - accuracy: 0.6058\n",
      "Epoch 31/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.2653 - accuracy: 0.6096\n",
      "Epoch 32/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.2562 - accuracy: 0.6127\n",
      "Epoch 33/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.2485 - accuracy: 0.6162\n",
      "Epoch 34/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.2405 - accuracy: 0.6179\n",
      "Epoch 35/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.2296 - accuracy: 0.6209\n",
      "Epoch 36/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.2231 - accuracy: 0.6215\n",
      "Epoch 37/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.2145 - accuracy: 0.6263\n",
      "Epoch 38/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.2070 - accuracy: 0.6265\n",
      "Epoch 39/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 1.1992 - accuracy: 0.6288\n",
      "Epoch 40/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.1935 - accuracy: 0.6299\n",
      "Epoch 41/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.1854 - accuracy: 0.6345\n",
      "Epoch 42/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.1786 - accuracy: 0.6355\n",
      "Epoch 43/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 1.1726 - accuracy: 0.6354\n",
      "Epoch 44/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.1655 - accuracy: 0.6387\n",
      "Epoch 45/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.1601 - accuracy: 0.6414\n",
      "Epoch 46/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.1547 - accuracy: 0.6447\n",
      "Epoch 47/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.1483 - accuracy: 0.6449\n",
      "Epoch 48/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.1432 - accuracy: 0.6444\n",
      "Epoch 49/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.1372 - accuracy: 0.6472\n",
      "Epoch 50/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.1322 - accuracy: 0.6476\n",
      "Epoch 51/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.1268 - accuracy: 0.6493\n",
      "Epoch 52/100\n",
      "2444/2444 [==============================] - 16s 6ms/step - loss: 1.1221 - accuracy: 0.6522\n",
      "Epoch 53/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.1153 - accuracy: 0.6533\n",
      "Epoch 54/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.1135 - accuracy: 0.6537\n",
      "Epoch 55/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.1082 - accuracy: 0.6554\n",
      "Epoch 56/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.1020 - accuracy: 0.6558\n",
      "Epoch 57/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0972 - accuracy: 0.6586\n",
      "Epoch 58/100\n",
      "2444/2444 [==============================] - 18s 7ms/step - loss: 1.0932 - accuracy: 0.6583\n",
      "Epoch 59/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 1.0889 - accuracy: 0.6593\n",
      "Epoch 60/100\n",
      "2444/2444 [==============================] - 16s 7ms/step - loss: 1.0845 - accuracy: 0.6595\n",
      "Epoch 61/100\n",
      "2444/2444 [==============================] - 16s 6ms/step - loss: 1.0798 - accuracy: 0.6622\n",
      "Epoch 62/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 1.0765 - accuracy: 0.6618\n",
      "Epoch 63/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0730 - accuracy: 0.6641\n",
      "Epoch 64/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0706 - accuracy: 0.6652\n",
      "Epoch 65/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0639 - accuracy: 0.6655\n",
      "Epoch 66/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0613 - accuracy: 0.6684\n",
      "Epoch 67/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0577 - accuracy: 0.6688\n",
      "Epoch 68/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0539 - accuracy: 0.6698\n",
      "Epoch 69/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0510 - accuracy: 0.6705\n",
      "Epoch 70/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0459 - accuracy: 0.6720\n",
      "Epoch 71/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0429 - accuracy: 0.6734\n",
      "Epoch 72/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0403 - accuracy: 0.6746\n",
      "Epoch 73/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0370 - accuracy: 0.6748\n",
      "Epoch 74/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0344 - accuracy: 0.6748\n",
      "Epoch 75/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0315 - accuracy: 0.6752\n",
      "Epoch 76/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0278 - accuracy: 0.6778\n",
      "Epoch 77/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0246 - accuracy: 0.6776\n",
      "Epoch 78/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 1.0224 - accuracy: 0.6779\n",
      "Epoch 79/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0207 - accuracy: 0.6804\n",
      "Epoch 80/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0153 - accuracy: 0.6801\n",
      "Epoch 81/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0132 - accuracy: 0.6809\n",
      "Epoch 82/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0109 - accuracy: 0.6819\n",
      "Epoch 83/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0084 - accuracy: 0.6836\n",
      "Epoch 84/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0051 - accuracy: 0.6838\n",
      "Epoch 85/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0011 - accuracy: 0.6848\n",
      "Epoch 86/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9977 - accuracy: 0.6858\n",
      "Epoch 87/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.9958 - accuracy: 0.6858\n",
      "Epoch 88/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9942 - accuracy: 0.6878\n",
      "Epoch 89/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9905 - accuracy: 0.6878\n",
      "Epoch 90/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9883 - accuracy: 0.6886\n",
      "Epoch 91/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9855 - accuracy: 0.6911\n",
      "Epoch 92/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.9810 - accuracy: 0.6896\n",
      "Epoch 93/100\n",
      "2444/2444 [==============================] - 16s 6ms/step - loss: 0.9825 - accuracy: 0.6889\n",
      "Epoch 94/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9781 - accuracy: 0.6907\n",
      "Epoch 95/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9752 - accuracy: 0.6903\n",
      "Epoch 96/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9747 - accuracy: 0.6915\n",
      "Epoch 97/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9696 - accuracy: 0.6943\n",
      "Epoch 98/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9689 - accuracy: 0.6925\n",
      "Epoch 99/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9661 - accuracy: 0.6949\n",
      "Epoch 100/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9646 - accuracy: 0.6954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21ed6cecbd0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CNN for top right quadrant\n",
    "\n",
    "# Define the input shape for each quadrant\n",
    "input_shape = (14, 14, 1)\n",
    "\n",
    "# Create a sequential model for the top left quadrant\n",
    "model_tr = Sequential()\n",
    "\n",
    "# Add a convolutional layer with 16 filters, 3x3 kernel size, and sigmoid activation\n",
    "model_tr.add(Conv2D(16, kernel_size=(3, 3), activation='sigmoid', input_shape=input_shape))\n",
    "\n",
    "# Add a max pooling layer with 2x2 pool size\n",
    "model_tr.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Add a convolutional layer with 32 filters, 3x3 kernel size, and sigmoid activation\n",
    "model_tr.add(Conv2D(32, kernel_size=(3, 3), activation='sigmoid'))\n",
    "\n",
    "# Add a max pooling layer with 2x2 pool size\n",
    "model_tr.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the output of the previous layer\n",
    "model_tr.add(Flatten())\n",
    "\n",
    "# Add a dense layer with 512 units and relu activation\n",
    "model_tr.add(Dense(512, activation='relu'))\n",
    "\n",
    "# Add the output layer with 46 units and softmax activation\n",
    "model_tr.add(Dense(46, activation='softmax'))\n",
    "\n",
    "# Compile the model with categorical crossentropy loss and Adam optimizer\n",
    "model_tr.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model_tr.summary()\n",
    "\n",
    "# Train the model on the top left quadrant dataset\n",
    "model_tr.fit(x_train_tr, train_labels_onehot, batch_size=32, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 12, 12, 16)        160       \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 6, 6, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 4, 4, 32)          4640      \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 2, 2, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 512)               66048     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 46)                23598     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 94,446\n",
      "Trainable params: 94,446\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "2444/2444 [==============================] - 13s 5ms/step - loss: 2.8102 - accuracy: 0.2350\n",
      "Epoch 2/100\n",
      "2444/2444 [==============================] - 16s 6ms/step - loss: 1.8336 - accuracy: 0.4508\n",
      "Epoch 3/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.5735 - accuracy: 0.5193\n",
      "Epoch 4/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.4149 - accuracy: 0.5617\n",
      "Epoch 5/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.3040 - accuracy: 0.5933\n",
      "Epoch 6/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.2215 - accuracy: 0.6171\n",
      "Epoch 7/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.1530 - accuracy: 0.6362\n",
      "Epoch 8/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0982 - accuracy: 0.6513\n",
      "Epoch 9/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0534 - accuracy: 0.6644\n",
      "Epoch 10/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0133 - accuracy: 0.6753\n",
      "Epoch 11/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9797 - accuracy: 0.6852\n",
      "Epoch 12/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9487 - accuracy: 0.6957\n",
      "Epoch 13/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9223 - accuracy: 0.7029\n",
      "Epoch 14/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8979 - accuracy: 0.7094\n",
      "Epoch 15/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8766 - accuracy: 0.7149\n",
      "Epoch 16/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8576 - accuracy: 0.7206\n",
      "Epoch 17/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8383 - accuracy: 0.7275\n",
      "Epoch 18/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8215 - accuracy: 0.7318\n",
      "Epoch 19/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8069 - accuracy: 0.7358\n",
      "Epoch 20/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7892 - accuracy: 0.7418\n",
      "Epoch 21/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7786 - accuracy: 0.7453\n",
      "Epoch 22/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7648 - accuracy: 0.7477\n",
      "Epoch 23/100\n",
      "2444/2444 [==============================] - 16s 6ms/step - loss: 0.7507 - accuracy: 0.7510\n",
      "Epoch 24/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7406 - accuracy: 0.7553\n",
      "Epoch 25/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7286 - accuracy: 0.7600\n",
      "Epoch 26/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7191 - accuracy: 0.7616\n",
      "Epoch 27/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7071 - accuracy: 0.7662\n",
      "Epoch 28/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.6991 - accuracy: 0.7685\n",
      "Epoch 29/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.6891 - accuracy: 0.7701\n",
      "Epoch 30/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.6799 - accuracy: 0.7740\n",
      "Epoch 31/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.6708 - accuracy: 0.7772\n",
      "Epoch 32/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.6622 - accuracy: 0.7792\n",
      "Epoch 33/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.6546 - accuracy: 0.7818\n",
      "Epoch 34/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.6469 - accuracy: 0.7851\n",
      "Epoch 35/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.6415 - accuracy: 0.7857\n",
      "Epoch 36/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.6322 - accuracy: 0.7884\n",
      "Epoch 37/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.6267 - accuracy: 0.7903\n",
      "Epoch 38/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.6195 - accuracy: 0.7929\n",
      "Epoch 39/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.6144 - accuracy: 0.7929\n",
      "Epoch 40/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.6076 - accuracy: 0.7971\n",
      "Epoch 41/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.6018 - accuracy: 0.7983\n",
      "Epoch 42/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.5977 - accuracy: 0.7990\n",
      "Epoch 43/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.5913 - accuracy: 0.8007\n",
      "Epoch 44/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.5871 - accuracy: 0.8021\n",
      "Epoch 45/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.5801 - accuracy: 0.8041\n",
      "Epoch 46/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.5747 - accuracy: 0.8068\n",
      "Epoch 47/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.5698 - accuracy: 0.8062\n",
      "Epoch 48/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.5660 - accuracy: 0.8091\n",
      "Epoch 49/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.5608 - accuracy: 0.8097\n",
      "Epoch 50/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.5575 - accuracy: 0.8093\n",
      "Epoch 51/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.5517 - accuracy: 0.8133\n",
      "Epoch 52/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.5490 - accuracy: 0.8136\n",
      "Epoch 53/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.5441 - accuracy: 0.8159\n",
      "Epoch 54/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.5386 - accuracy: 0.8168\n",
      "Epoch 55/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.5366 - accuracy: 0.8175\n",
      "Epoch 56/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.5311 - accuracy: 0.8187\n",
      "Epoch 57/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.5277 - accuracy: 0.8201\n",
      "Epoch 58/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.5233 - accuracy: 0.8210\n",
      "Epoch 59/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.5200 - accuracy: 0.8231\n",
      "Epoch 60/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.5171 - accuracy: 0.8234\n",
      "Epoch 61/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.5144 - accuracy: 0.8242\n",
      "Epoch 62/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.5084 - accuracy: 0.8260\n",
      "Epoch 63/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.5055 - accuracy: 0.8263\n",
      "Epoch 64/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.5024 - accuracy: 0.8274\n",
      "Epoch 65/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.5000 - accuracy: 0.8282\n",
      "Epoch 66/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.4951 - accuracy: 0.8297\n",
      "Epoch 67/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.4933 - accuracy: 0.8316\n",
      "Epoch 68/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.4893 - accuracy: 0.8310\n",
      "Epoch 69/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.4865 - accuracy: 0.8320\n",
      "Epoch 70/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.4805 - accuracy: 0.8344\n",
      "Epoch 71/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.4799 - accuracy: 0.8342\n",
      "Epoch 72/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.4775 - accuracy: 0.8353\n",
      "Epoch 73/100\n",
      "2444/2444 [==============================] - 16s 7ms/step - loss: 0.4744 - accuracy: 0.8359\n",
      "Epoch 74/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.4705 - accuracy: 0.8372\n",
      "Epoch 75/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.4703 - accuracy: 0.8385\n",
      "Epoch 76/100\n",
      "2444/2444 [==============================] - 16s 6ms/step - loss: 0.4666 - accuracy: 0.8393\n",
      "Epoch 77/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.4647 - accuracy: 0.8399\n",
      "Epoch 78/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.4615 - accuracy: 0.8402\n",
      "Epoch 79/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.4588 - accuracy: 0.8414\n",
      "Epoch 80/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.4559 - accuracy: 0.8417\n",
      "Epoch 81/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.4531 - accuracy: 0.8423\n",
      "Epoch 82/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.4506 - accuracy: 0.8434\n",
      "Epoch 83/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.4474 - accuracy: 0.8436\n",
      "Epoch 84/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.4462 - accuracy: 0.8449\n",
      "Epoch 85/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.4459 - accuracy: 0.8449\n",
      "Epoch 86/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.4414 - accuracy: 0.8458\n",
      "Epoch 87/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.4379 - accuracy: 0.8483\n",
      "Epoch 88/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.4359 - accuracy: 0.8485\n",
      "Epoch 89/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.4352 - accuracy: 0.8482\n",
      "Epoch 90/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.4318 - accuracy: 0.8492\n",
      "Epoch 91/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.4306 - accuracy: 0.8494\n",
      "Epoch 92/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.4269 - accuracy: 0.8509\n",
      "Epoch 93/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.4267 - accuracy: 0.8511\n",
      "Epoch 94/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.4228 - accuracy: 0.8518\n",
      "Epoch 95/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.4211 - accuracy: 0.8532\n",
      "Epoch 96/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.4203 - accuracy: 0.8541\n",
      "Epoch 97/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.4190 - accuracy: 0.8542\n",
      "Epoch 98/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.4157 - accuracy: 0.8545\n",
      "Epoch 99/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.4142 - accuracy: 0.8554\n",
      "Epoch 100/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.4120 - accuracy: 0.8556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21edd55d010>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CNN for bottom left quadrant\n",
    "\n",
    "# Define the input shape for each quadrant\n",
    "input_shape = (14, 14, 1)\n",
    "\n",
    "# Create a sequential model for the top left quadrant\n",
    "model_bl = Sequential()\n",
    "\n",
    "# Add a convolutional layer with 16 filters, 3x3 kernel size, and sigmoid activation\n",
    "model_bl.add(Conv2D(16, kernel_size=(3, 3), activation='sigmoid', input_shape=input_shape))\n",
    "\n",
    "# Add a max pooling layer with 2x2 pool size\n",
    "model_bl.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Add a convolutional layer with 32 filters, 3x3 kernel size, and sigmoid activation\n",
    "model_bl.add(Conv2D(32, kernel_size=(3, 3), activation='sigmoid'))\n",
    "\n",
    "# Add a max pooling layer with 2x2 pool size\n",
    "model_bl.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the output of the previous layer\n",
    "model_bl.add(Flatten())\n",
    "\n",
    "# Add a dense layer with 512 units and relu activation\n",
    "model_bl.add(Dense(512, activation='relu'))\n",
    "\n",
    "# Add the output layer with 46 units and softmax activation\n",
    "model_bl.add(Dense(46, activation='softmax'))\n",
    "\n",
    "# Compile the model with categorical crossentropy loss and Adam optimizer\n",
    "model_bl.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model_bl.summary()\n",
    "\n",
    "# Train the model on the top left quadrant dataset\n",
    "model_bl.fit(x_train_bl, train_labels_onehot, batch_size=32, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_10 (Conv2D)          (None, 12, 12, 16)        160       \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 6, 6, 16)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 4, 4, 32)          4640      \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 2, 2, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 512)               66048     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 46)                23598     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 94,446\n",
      "Trainable params: 94,446\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "2444/2444 [==============================] - 13s 5ms/step - loss: 3.0397 - accuracy: 0.1736\n",
      "Epoch 2/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 2.1594 - accuracy: 0.3526\n",
      "Epoch 3/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.9166 - accuracy: 0.4122\n",
      "Epoch 4/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.7847 - accuracy: 0.4481\n",
      "Epoch 5/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.6943 - accuracy: 0.4693\n",
      "Epoch 6/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.6224 - accuracy: 0.4908\n",
      "Epoch 7/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.5631 - accuracy: 0.5062\n",
      "Epoch 8/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 1.5150 - accuracy: 0.5210\n",
      "Epoch 9/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 1.4703 - accuracy: 0.5336\n",
      "Epoch 10/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 1.4332 - accuracy: 0.5445\n",
      "Epoch 11/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.4000 - accuracy: 0.5550\n",
      "Epoch 12/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.3699 - accuracy: 0.5629\n",
      "Epoch 13/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.3433 - accuracy: 0.5717\n",
      "Epoch 14/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.3194 - accuracy: 0.5788\n",
      "Epoch 15/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.2954 - accuracy: 0.5849\n",
      "Epoch 16/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.2758 - accuracy: 0.5913\n",
      "Epoch 17/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 1.2573 - accuracy: 0.5980\n",
      "Epoch 18/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.2395 - accuracy: 0.6037\n",
      "Epoch 19/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 1.2226 - accuracy: 0.6063\n",
      "Epoch 20/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.2096 - accuracy: 0.6108\n",
      "Epoch 21/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.1942 - accuracy: 0.6157\n",
      "Epoch 22/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.1820 - accuracy: 0.6184\n",
      "Epoch 23/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 1.1697 - accuracy: 0.6226\n",
      "Epoch 24/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.1558 - accuracy: 0.6264\n",
      "Epoch 25/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.1462 - accuracy: 0.6302\n",
      "Epoch 26/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 1.1339 - accuracy: 0.6330\n",
      "Epoch 27/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.1240 - accuracy: 0.6366\n",
      "Epoch 28/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 1.1127 - accuracy: 0.6400\n",
      "Epoch 29/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.1042 - accuracy: 0.6435\n",
      "Epoch 30/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0953 - accuracy: 0.6458\n",
      "Epoch 31/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0853 - accuracy: 0.6490\n",
      "Epoch 32/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0777 - accuracy: 0.6491\n",
      "Epoch 33/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0677 - accuracy: 0.6546\n",
      "Epoch 34/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 1.0637 - accuracy: 0.6542\n",
      "Epoch 35/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 1.0543 - accuracy: 0.6587\n",
      "Epoch 36/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 1.0464 - accuracy: 0.6609\n",
      "Epoch 37/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0380 - accuracy: 0.6625\n",
      "Epoch 38/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0334 - accuracy: 0.6645\n",
      "Epoch 39/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 1.0261 - accuracy: 0.6667\n",
      "Epoch 40/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0189 - accuracy: 0.6678\n",
      "Epoch 41/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0142 - accuracy: 0.6692\n",
      "Epoch 42/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0073 - accuracy: 0.6723\n",
      "Epoch 43/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0019 - accuracy: 0.6739\n",
      "Epoch 44/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9941 - accuracy: 0.6763\n",
      "Epoch 45/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9896 - accuracy: 0.6784\n",
      "Epoch 46/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9852 - accuracy: 0.6794\n",
      "Epoch 47/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9802 - accuracy: 0.6808\n",
      "Epoch 48/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9753 - accuracy: 0.6821\n",
      "Epoch 49/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9686 - accuracy: 0.6826\n",
      "Epoch 50/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.9648 - accuracy: 0.6860\n",
      "Epoch 51/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9607 - accuracy: 0.6864\n",
      "Epoch 52/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.9554 - accuracy: 0.6869\n",
      "Epoch 53/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9509 - accuracy: 0.6893\n",
      "Epoch 54/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.9463 - accuracy: 0.6914\n",
      "Epoch 55/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9431 - accuracy: 0.6919\n",
      "Epoch 56/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9371 - accuracy: 0.6952\n",
      "Epoch 57/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9343 - accuracy: 0.6950\n",
      "Epoch 58/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9303 - accuracy: 0.6961\n",
      "Epoch 59/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.9268 - accuracy: 0.6966\n",
      "Epoch 60/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9200 - accuracy: 0.6989\n",
      "Epoch 61/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9174 - accuracy: 0.7017\n",
      "Epoch 62/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9150 - accuracy: 0.7019\n",
      "Epoch 63/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9113 - accuracy: 0.7019\n",
      "Epoch 64/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9066 - accuracy: 0.7033\n",
      "Epoch 65/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9043 - accuracy: 0.7045\n",
      "Epoch 66/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8990 - accuracy: 0.7053\n",
      "Epoch 67/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8948 - accuracy: 0.7064\n",
      "Epoch 68/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8937 - accuracy: 0.7053\n",
      "Epoch 69/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8901 - accuracy: 0.7096\n",
      "Epoch 70/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.8854 - accuracy: 0.7106\n",
      "Epoch 71/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8833 - accuracy: 0.7110\n",
      "Epoch 72/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.8774 - accuracy: 0.7146\n",
      "Epoch 73/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8758 - accuracy: 0.7136\n",
      "Epoch 74/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8737 - accuracy: 0.7132\n",
      "Epoch 75/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8699 - accuracy: 0.7149\n",
      "Epoch 76/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8663 - accuracy: 0.7182\n",
      "Epoch 77/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.8629 - accuracy: 0.7181\n",
      "Epoch 78/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8611 - accuracy: 0.7179\n",
      "Epoch 79/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.8590 - accuracy: 0.7180\n",
      "Epoch 80/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.8562 - accuracy: 0.7205\n",
      "Epoch 81/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8538 - accuracy: 0.7206\n",
      "Epoch 82/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8493 - accuracy: 0.7216\n",
      "Epoch 83/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8472 - accuracy: 0.7228\n",
      "Epoch 84/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8430 - accuracy: 0.7226\n",
      "Epoch 85/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8427 - accuracy: 0.7239\n",
      "Epoch 86/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.8379 - accuracy: 0.7263\n",
      "Epoch 87/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8382 - accuracy: 0.7253\n",
      "Epoch 88/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8347 - accuracy: 0.7266\n",
      "Epoch 89/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.8305 - accuracy: 0.7286\n",
      "Epoch 90/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.8288 - accuracy: 0.7278\n",
      "Epoch 91/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.8266 - accuracy: 0.7299\n",
      "Epoch 92/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.8228 - accuracy: 0.7307\n",
      "Epoch 93/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.8216 - accuracy: 0.7320\n",
      "Epoch 94/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8198 - accuracy: 0.7308\n",
      "Epoch 95/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.8180 - accuracy: 0.7322\n",
      "Epoch 96/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.8155 - accuracy: 0.7327\n",
      "Epoch 97/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.8145 - accuracy: 0.7327\n",
      "Epoch 98/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8108 - accuracy: 0.7338\n",
      "Epoch 99/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.8093 - accuracy: 0.7338\n",
      "Epoch 100/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.8043 - accuracy: 0.7362\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21ed6c54f50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CNN for bottom right quadrant\n",
    "\n",
    "# Define the input shape for each quadrant\n",
    "input_shape = (14, 14, 1)\n",
    "\n",
    "# Create a sequential model for the top left quadrant\n",
    "model_br = Sequential()\n",
    "\n",
    "# Add a convolutional layer with 16 filters, 3x3 kernel size, and sigmoid activation\n",
    "model_br.add(Conv2D(16, kernel_size=(3, 3), activation='sigmoid', input_shape=input_shape))\n",
    "\n",
    "# Add a max pooling layer with 2x2 pool size\n",
    "model_br.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Add a convolutional layer with 32 filters, 3x3 kernel size, and sigmoid activation\n",
    "model_br.add(Conv2D(32, kernel_size=(3, 3), activation='sigmoid'))\n",
    "\n",
    "# Add a max pooling layer with 2x2 pool size\n",
    "model_br.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the output of the previous layer\n",
    "model_br.add(Flatten())\n",
    "\n",
    "# Add a dense layer with 512 units and relu activation\n",
    "model_br.add(Dense(512, activation='relu'))\n",
    "\n",
    "# Add the output layer with 46 units and softmax activation\n",
    "model_br.add(Dense(46, activation='softmax'))\n",
    "\n",
    "# Compile the model with categorical crossentropy loss and Adam optimizer\n",
    "model_br.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model_br.summary()\n",
    "\n",
    "# Train the model on the top left quadrant dataset\n",
    "model_br.fit(x_train_br, train_labels_onehot, batch_size=32, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 12, 12, 16)        160       \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 6, 6, 16)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 4, 4, 32)          4640      \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 2, 2, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 512)               66048     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 46)                23598     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 94,446\n",
      "Trainable params: 94,446\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "2444/2444 [==============================] - 13s 5ms/step - loss: 2.9171 - accuracy: 0.2209\n",
      "Epoch 2/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.9457 - accuracy: 0.4383\n",
      "Epoch 3/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.5869 - accuracy: 0.5315\n",
      "Epoch 4/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.3768 - accuracy: 0.5882\n",
      "Epoch 5/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.2264 - accuracy: 0.6297\n",
      "Epoch 6/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.1201 - accuracy: 0.6558\n",
      "Epoch 7/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0375 - accuracy: 0.6786\n",
      "Epoch 8/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9699 - accuracy: 0.6997\n",
      "Epoch 9/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9154 - accuracy: 0.7143\n",
      "Epoch 10/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8687 - accuracy: 0.7266\n",
      "Epoch 11/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8299 - accuracy: 0.7388\n",
      "Epoch 12/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7929 - accuracy: 0.7490\n",
      "Epoch 13/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7614 - accuracy: 0.7590\n",
      "Epoch 14/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7334 - accuracy: 0.7662\n",
      "Epoch 15/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7092 - accuracy: 0.7737\n",
      "Epoch 16/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.6852 - accuracy: 0.7798\n",
      "Epoch 17/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.6649 - accuracy: 0.7859\n",
      "Epoch 18/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.6474 - accuracy: 0.7898\n",
      "Epoch 19/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.6291 - accuracy: 0.7960\n",
      "Epoch 20/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.6113 - accuracy: 0.8011\n",
      "Epoch 21/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.5965 - accuracy: 0.8053\n",
      "Epoch 22/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.5826 - accuracy: 0.8090\n",
      "Epoch 23/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.5687 - accuracy: 0.8127\n",
      "Epoch 24/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.5558 - accuracy: 0.8171\n",
      "Epoch 25/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.5434 - accuracy: 0.8202\n",
      "Epoch 26/100\n",
      "2444/2444 [==============================] - 16s 6ms/step - loss: 0.5333 - accuracy: 0.8237\n",
      "Epoch 27/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.5259 - accuracy: 0.8251\n",
      "Epoch 28/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.5127 - accuracy: 0.8284\n",
      "Epoch 29/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.5033 - accuracy: 0.8334\n",
      "Epoch 30/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.4936 - accuracy: 0.8356\n",
      "Epoch 31/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.4858 - accuracy: 0.8373\n",
      "Epoch 32/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.4762 - accuracy: 0.8400\n",
      "Epoch 33/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.4679 - accuracy: 0.8434\n",
      "Epoch 34/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.4618 - accuracy: 0.8437\n",
      "Epoch 35/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.4536 - accuracy: 0.8477\n",
      "Epoch 36/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.4451 - accuracy: 0.8500\n",
      "Epoch 37/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.4391 - accuracy: 0.8534\n",
      "Epoch 38/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.4323 - accuracy: 0.8529\n",
      "Epoch 39/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.4257 - accuracy: 0.8557\n",
      "Epoch 40/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.4178 - accuracy: 0.8577\n",
      "Epoch 41/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.4137 - accuracy: 0.8598\n",
      "Epoch 42/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.4078 - accuracy: 0.8612\n",
      "Epoch 43/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.3997 - accuracy: 0.8634\n",
      "Epoch 44/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.3937 - accuracy: 0.8652\n",
      "Epoch 45/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.3908 - accuracy: 0.8660\n",
      "Epoch 46/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.3849 - accuracy: 0.8682\n",
      "Epoch 47/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.3800 - accuracy: 0.8694\n",
      "Epoch 48/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.3736 - accuracy: 0.8722\n",
      "Epoch 49/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.3682 - accuracy: 0.8730\n",
      "Epoch 50/100\n",
      "2444/2444 [==============================] - 17s 7ms/step - loss: 0.3650 - accuracy: 0.8734\n",
      "Epoch 51/100\n",
      "2444/2444 [==============================] - 16s 6ms/step - loss: 0.3590 - accuracy: 0.8753\n",
      "Epoch 52/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.3550 - accuracy: 0.8774\n",
      "Epoch 53/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.3510 - accuracy: 0.8778\n",
      "Epoch 54/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.3454 - accuracy: 0.8798\n",
      "Epoch 55/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.3409 - accuracy: 0.8819\n",
      "Epoch 56/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.3365 - accuracy: 0.8832\n",
      "Epoch 57/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.3325 - accuracy: 0.8843\n",
      "Epoch 58/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.3279 - accuracy: 0.8863\n",
      "Epoch 59/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.3247 - accuracy: 0.8857\n",
      "Epoch 60/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.3213 - accuracy: 0.8881\n",
      "Epoch 61/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.3167 - accuracy: 0.8896\n",
      "Epoch 62/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.3144 - accuracy: 0.8901\n",
      "Epoch 63/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.3085 - accuracy: 0.8922\n",
      "Epoch 64/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.3077 - accuracy: 0.8919\n",
      "Epoch 65/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.3020 - accuracy: 0.8944\n",
      "Epoch 66/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.2990 - accuracy: 0.8948\n",
      "Epoch 67/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.2951 - accuracy: 0.8958\n",
      "Epoch 68/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.2929 - accuracy: 0.8961\n",
      "Epoch 69/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.2888 - accuracy: 0.8976\n",
      "Epoch 70/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.2862 - accuracy: 0.9002\n",
      "Epoch 71/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.2839 - accuracy: 0.8995\n",
      "Epoch 72/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.2812 - accuracy: 0.9009\n",
      "Epoch 73/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.2776 - accuracy: 0.9011\n",
      "Epoch 74/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.2754 - accuracy: 0.9023\n",
      "Epoch 75/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.2732 - accuracy: 0.9028\n",
      "Epoch 76/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.2701 - accuracy: 0.9032\n",
      "Epoch 77/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.2669 - accuracy: 0.9045\n",
      "Epoch 78/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.2642 - accuracy: 0.9058\n",
      "Epoch 79/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.2604 - accuracy: 0.9068\n",
      "Epoch 80/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.2577 - accuracy: 0.9081\n",
      "Epoch 81/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.2553 - accuracy: 0.9077\n",
      "Epoch 82/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.2542 - accuracy: 0.9080\n",
      "Epoch 83/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.2517 - accuracy: 0.9109\n",
      "Epoch 84/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.2477 - accuracy: 0.9107\n",
      "Epoch 85/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.2459 - accuracy: 0.9108\n",
      "Epoch 86/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.2433 - accuracy: 0.9116\n",
      "Epoch 87/100\n",
      "2444/2444 [==============================] - 18s 8ms/step - loss: 0.2423 - accuracy: 0.9127\n",
      "Epoch 88/100\n",
      "2444/2444 [==============================] - 16s 6ms/step - loss: 0.2394 - accuracy: 0.9140\n",
      "Epoch 89/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.2342 - accuracy: 0.9149\n",
      "Epoch 90/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.2346 - accuracy: 0.9154\n",
      "Epoch 91/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.2317 - accuracy: 0.9147\n",
      "Epoch 92/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.2298 - accuracy: 0.9157\n",
      "Epoch 93/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.2263 - accuracy: 0.9186\n",
      "Epoch 94/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.2268 - accuracy: 0.9179\n",
      "Epoch 95/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.2217 - accuracy: 0.9200\n",
      "Epoch 96/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.2214 - accuracy: 0.9196\n",
      "Epoch 97/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.2182 - accuracy: 0.9212\n",
      "Epoch 98/100\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 0.2174 - accuracy: 0.9202\n",
      "Epoch 99/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.2153 - accuracy: 0.9222\n",
      "Epoch 100/100\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.2142 - accuracy: 0.9222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21ee0254f50>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CNN for center quadrant\n",
    "\n",
    "# Define the input shape for each quadrant\n",
    "input_shape = (14, 14, 1)\n",
    "\n",
    "# Create a sequential model for the top left quadrant\n",
    "model_c = Sequential()\n",
    "\n",
    "# Add a convolutional layer with 16 filters, 3x3 kernel size, and sigmoid activation\n",
    "model_c.add(Conv2D(16, kernel_size=(3, 3), activation='sigmoid', input_shape=input_shape))\n",
    "\n",
    "# Add a max pooling layer with 2x2 pool size\n",
    "model_c.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Add a convolutional layer with 32 filters, 3x3 kernel size, and sigmoid activation\n",
    "model_c.add(Conv2D(32, kernel_size=(3, 3), activation='sigmoid'))\n",
    "\n",
    "# Add a max pooling layer with 2x2 pool size\n",
    "model_c.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the output of the previous layer\n",
    "model_c.add(Flatten())\n",
    "\n",
    "# Add a dense layer with 512 units and relu activation\n",
    "model_c.add(Dense(512, activation='relu'))\n",
    "\n",
    "# Add the output layer with 46 units and softmax activation\n",
    "model_c.add(Dense(46, activation='softmax'))\n",
    "\n",
    "# Compile the model with categorical crossentropy loss and Adam optimizer\n",
    "model_c.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model_c.summary()\n",
    "\n",
    "# Train the model on the top left quadrant dataset\n",
    "model_c.fit(x_train_c, train_labels_onehot, batch_size=32, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2444/2444 [==============================] - 4s 2ms/step\n",
      "2444/2444 [==============================] - 6s 3ms/step\n",
      "2444/2444 [==============================] - 6s 2ms/step\n",
      "2444/2444 [==============================] - 6s 2ms/step\n",
      "2444/2444 [==============================] - 6s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# create new models to extract features from the last dense layer\n",
    "model_tl_features = Model(inputs=model_tl.input, outputs=model_tl.get_layer('dense_4').output)\n",
    "model_tr_features = Model(inputs=model_tr.input, outputs=model_tr.get_layer('dense_6').output)\n",
    "model_bl_features = Model(inputs=model_bl.input, outputs=model_bl.get_layer('dense_8').output)\n",
    "model_br_features = Model(inputs=model_br.input, outputs=model_br.get_layer('dense_10').output)\n",
    "model_c_features = Model(inputs=model_c.input, outputs=model_c.get_layer('dense_12').output)\n",
    "\n",
    "# extract features from the last dense layer for each quadrant\n",
    "tl_features = model_tl_features.predict(x_train_tl)\n",
    "tr_features = model_tr_features.predict(x_train_tr)\n",
    "bl_features = model_bl_features.predict(x_train_bl)\n",
    "br_features = model_br_features.predict(x_train_br)\n",
    "center_features = model_c_features.predict(x_train_c)\n",
    "\n",
    "# concatenate the features from all 5 quadrants into a single input\n",
    "features = np.concatenate((tl_features, tr_features, bl_features, br_features, center_features), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2444/2444 [==============================] - 391s 160ms/step - loss: 0.3150 - accuracy: 0.9142\n",
      "Epoch 2/10\n",
      "2444/2444 [==============================] - 386s 158ms/step - loss: 0.1425 - accuracy: 0.9676\n",
      "Epoch 3/10\n",
      "2444/2444 [==============================] - 391s 160ms/step - loss: 0.1218 - accuracy: 0.9753\n",
      "Epoch 4/10\n",
      "2444/2444 [==============================] - 388s 159ms/step - loss: 0.0864 - accuracy: 0.9828\n",
      "Epoch 5/10\n",
      "2444/2444 [==============================] - 389s 159ms/step - loss: 0.0866 - accuracy: 0.9846\n",
      "Epoch 6/10\n",
      "2444/2444 [==============================] - 392s 161ms/step - loss: 0.0755 - accuracy: 0.9867\n",
      "Epoch 7/10\n",
      "2444/2444 [==============================] - 375s 153ms/step - loss: 0.0680 - accuracy: 0.9881\n",
      "Epoch 8/10\n",
      "2444/2444 [==============================] - 373s 152ms/step - loss: 0.0620 - accuracy: 0.9897\n",
      "Epoch 9/10\n",
      "2444/2444 [==============================] - 377s 154ms/step - loss: 0.0591 - accuracy: 0.9902\n",
      "Epoch 10/10\n",
      "2444/2444 [==============================] - 378s 155ms/step - loss: 0.0733 - accuracy: 0.9904\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# define the DNN classifier model\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(2560, activation='relu', input_shape=(features.shape[1],)))\n",
    "classifier.add(Dense(1000, activation='relu'))\n",
    "classifier.add(Dense(1000, activation='relu'))\n",
    "classifier.add(Dense(1000, activation='relu'))\n",
    "classifier.add(Dense(46, activation='softmax'))\n",
    "\n",
    "# compile the model\n",
    "classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = classifier.fit(features, train_labels_onehot, batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the test data for prediction and testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels_int = label_encoder.fit_transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the integer labels to one-hot encoding\n",
    "test_labels_onehot = to_categorical(test_labels_int, num_classes=46)\n",
    "\n",
    "# Split the data into the five quadrants\n",
    "x_test_tl = test_images[:,:14,:14].reshape(-1, 14, 14, 1)\n",
    "x_test_tr = test_images[:,:14,14:].reshape(-1, 14, 14, 1)\n",
    "x_test_bl = test_images[:,14:,:14].reshape(-1, 14, 14, 1)\n",
    "x_test_br = test_images[:,14:,14:].reshape(-1, 14, 14, 1)\n",
    "x_test_c = test_images[:,7:21,7:21].reshape(-1, 14, 14, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432/432 [==============================] - 1s 2ms/step\n",
      "432/432 [==============================] - 1s 2ms/step\n",
      "432/432 [==============================] - 1s 2ms/step\n",
      "432/432 [==============================] - 1s 2ms/step\n",
      "432/432 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# extract features from the last dense layer for each quadrant\n",
    "tl_features_test = model_tl_features.predict(x_test_tl)\n",
    "tr_features_test = model_tr_features.predict(x_test_tr)\n",
    "bl_features_test = model_bl_features.predict(x_test_bl)\n",
    "br_features_test = model_br_features.predict(x_test_br)\n",
    "center_features_test = model_c_features.predict(x_test_c)\n",
    "\n",
    "# concatenate the features from all 5 quadrants into a single input\n",
    "features_test = np.concatenate((tl_features_test, tr_features_test, bl_features_test, br_features_test, center_features_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to disk\n",
    "classifier.save(\"model_b32e100_b32e10.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432/432 [==============================] - 7s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "test_predictions = classifier.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "accuracy = accuracy_score(test_labels_int, test_predictions.argmax(axis=1))\n",
    "# precision = precision_score(test_labels_int, test_predictions.argmax(axis=1), average='weighted', zero_division=1)\n",
    "recall = recall_score(test_labels_int, test_predictions.argmax(axis=1), average='weighted')\n",
    "f1 = f1_score(test_labels_int, test_predictions.argmax(axis=1), average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9692753623188406\n",
      "Recall: 0.9692753623188406\n",
      "F1 Score: 0.9692700120644275\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', accuracy)\n",
    "# print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1 Score:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
