{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the train and test folders\n",
    "train_path = 'C:/A/code/VSC/python/test/cropped_DevanagariHandwrittenCharacterDataset/Train/'\n",
    "test_path = 'C:/A/code/VSC/python/test/cropped_DevanagariHandwrittenCharacterDataset/Test/'\n",
    "\n",
    "# Define a function to load and preprocess the images\n",
    "def load_images(path):\n",
    "    # Create empty lists to store the images and labels\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    # Loop through each folder (which represents a class) in the path\n",
    "    for folder in os.listdir(path):\n",
    "        # Get the path to the folder\n",
    "        folder_path = os.path.join(path, folder)\n",
    "        # Loop through each image in the folder\n",
    "        for file in os.listdir(folder_path):\n",
    "            # Get the path to the image file\n",
    "            img_path = os.path.join(folder_path, file)\n",
    "            # Load the image using OpenCV\n",
    "            img = cv2.imread(img_path)\n",
    "            # Convert the image to grayscale\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            # Normalize the pixel values of the images\n",
    "            img = img.astype('float32') / 255.0\n",
    "            # Append the image to the images list\n",
    "            images.append(img)\n",
    "            # Append the label to the labels list\n",
    "            labels.append(folder)\n",
    "\n",
    "    # Convert the images and labels lists to NumPy arrays\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    # Return the images and labels arrays\n",
    "    return images, labels\n",
    "\n",
    "# Load the train images and labels\n",
    "train_images, train_labels = load_images(train_path)\n",
    "\n",
    "# Load the test images and labels\n",
    "test_images, test_labels = load_images(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Convert the string labels to integer labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_int = label_encoder.fit_transform(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the integer labels to one-hot encoding\n",
    "train_labels_onehot = to_categorical(train_labels_int, num_classes=46)\n",
    "\n",
    "# Split the data into the five quadrants\n",
    "x_train_tl = train_images[:,:14,:14].reshape(-1, 14, 14, 1)\n",
    "x_train_tr = train_images[:,:14,14:].reshape(-1, 14, 14, 1)\n",
    "x_train_bl = train_images[:,14:,:14].reshape(-1, 14, 14, 1)\n",
    "x_train_br = train_images[:,14:,14:].reshape(-1, 14, 14, 1)\n",
    "x_train_c = train_images[:,7:21,7:21].reshape(-1, 14, 14, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 12, 12, 16)        160       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 6, 6, 16)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 4, 4, 32)          4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 2, 2, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               66048     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 46)                23598     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 94,446\n",
      "Trainable params: 94,446\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "4888/4888 [==============================] - 17s 3ms/step - loss: 2.8356 - accuracy: 0.2176\n",
      "Epoch 2/25\n",
      "4888/4888 [==============================] - 16s 3ms/step - loss: 2.0495 - accuracy: 0.3934\n",
      "Epoch 3/25\n",
      "4888/4888 [==============================] - 18s 4ms/step - loss: 1.8098 - accuracy: 0.4554\n",
      "Epoch 4/25\n",
      "4888/4888 [==============================] - 19s 4ms/step - loss: 1.6579 - accuracy: 0.4956\n",
      "Epoch 5/25\n",
      "4888/4888 [==============================] - 18s 4ms/step - loss: 1.5455 - accuracy: 0.5281\n",
      "Epoch 6/25\n",
      "4888/4888 [==============================] - 18s 4ms/step - loss: 1.4608 - accuracy: 0.5505\n",
      "Epoch 7/25\n",
      "4888/4888 [==============================] - 19s 4ms/step - loss: 1.3924 - accuracy: 0.5693\n",
      "Epoch 8/25\n",
      "4888/4888 [==============================] - 17s 4ms/step - loss: 1.3370 - accuracy: 0.5837\n",
      "Epoch 9/25\n",
      "4888/4888 [==============================] - 21s 4ms/step - loss: 1.2880 - accuracy: 0.5969\n",
      "Epoch 10/25\n",
      "4888/4888 [==============================] - 20s 4ms/step - loss: 1.2472 - accuracy: 0.6103\n",
      "Epoch 11/25\n",
      "4888/4888 [==============================] - 21s 4ms/step - loss: 1.2142 - accuracy: 0.6182\n",
      "Epoch 12/25\n",
      "4888/4888 [==============================] - 23s 5ms/step - loss: 1.1813 - accuracy: 0.6284\n",
      "Epoch 13/25\n",
      "4888/4888 [==============================] - 24s 5ms/step - loss: 1.1539 - accuracy: 0.6358\n",
      "Epoch 14/25\n",
      "4888/4888 [==============================] - 25s 5ms/step - loss: 1.1281 - accuracy: 0.6434\n",
      "Epoch 15/25\n",
      "4888/4888 [==============================] - 25s 5ms/step - loss: 1.1038 - accuracy: 0.6495\n",
      "Epoch 16/25\n",
      "4888/4888 [==============================] - 25s 5ms/step - loss: 1.0839 - accuracy: 0.6555\n",
      "Epoch 17/25\n",
      "4888/4888 [==============================] - 25s 5ms/step - loss: 1.0669 - accuracy: 0.6589\n",
      "Epoch 18/25\n",
      "4888/4888 [==============================] - 26s 5ms/step - loss: 1.0484 - accuracy: 0.6652\n",
      "Epoch 19/25\n",
      "4888/4888 [==============================] - 26s 5ms/step - loss: 1.0306 - accuracy: 0.6712\n",
      "Epoch 20/25\n",
      "4888/4888 [==============================] - 25s 5ms/step - loss: 1.0162 - accuracy: 0.6727\n",
      "Epoch 21/25\n",
      "4888/4888 [==============================] - 26s 5ms/step - loss: 1.0018 - accuracy: 0.6801\n",
      "Epoch 22/25\n",
      "4888/4888 [==============================] - 25s 5ms/step - loss: 0.9871 - accuracy: 0.6819\n",
      "Epoch 23/25\n",
      "4888/4888 [==============================] - 25s 5ms/step - loss: 0.9743 - accuracy: 0.6866\n",
      "Epoch 24/25\n",
      "4888/4888 [==============================] - 25s 5ms/step - loss: 0.9625 - accuracy: 0.6890\n",
      "Epoch 25/25\n",
      "4888/4888 [==============================] - 25s 5ms/step - loss: 0.9516 - accuracy: 0.6929\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28bebe42a90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CNN for top left quadrant\n",
    "\n",
    "# Define the input shape for each quadrant\n",
    "input_shape = (14, 14, 1)\n",
    "\n",
    "# Create a sequential model for the top left quadrant\n",
    "model_tl = Sequential()\n",
    "\n",
    "# Add a convolutional layer with 16 filters, 3x3 kernel size, and sigmoid activation\n",
    "model_tl.add(Conv2D(16, kernel_size=(3, 3), activation='sigmoid', input_shape=input_shape))\n",
    "\n",
    "# Add a max pooling layer with 2x2 pool size\n",
    "model_tl.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Add a convolutional layer with 32 filters, 3x3 kernel size, and sigmoid activation\n",
    "model_tl.add(Conv2D(32, kernel_size=(3, 3), activation='sigmoid'))\n",
    "\n",
    "# Add a max pooling layer with 2x2 pool size\n",
    "model_tl.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the output of the previous layer\n",
    "model_tl.add(Flatten())\n",
    "\n",
    "# Add a dense layer with 512 units and relu activation\n",
    "model_tl.add(Dense(512, activation='relu'))\n",
    "\n",
    "# Add the output layer with 46 units and softmax activation\n",
    "model_tl.add(Dense(46, activation='softmax'))\n",
    "\n",
    "# Compile the model with categorical crossentropy loss and Adam optimizer\n",
    "model_tl.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model_tl.summary()\n",
    "\n",
    "# Train the model on the top left quadrant dataset\n",
    "model_tl.fit(x_train_tl, train_labels_onehot, batch_size=16, epochs=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 12, 12, 16)        160       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 4, 4, 32)          4640      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 2, 2, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               66048     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 46)                23598     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 94,446\n",
      "Trainable params: 94,446\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "4888/4888 [==============================] - 23s 4ms/step - loss: 3.1335 - accuracy: 0.1619\n",
      "Epoch 2/25\n",
      "4888/4888 [==============================] - 24s 5ms/step - loss: 2.4014 - accuracy: 0.3120\n",
      "Epoch 3/25\n",
      "4888/4888 [==============================] - 28s 6ms/step - loss: 2.1397 - accuracy: 0.3770\n",
      "Epoch 4/25\n",
      "4888/4888 [==============================] - 25s 5ms/step - loss: 1.9834 - accuracy: 0.4165\n",
      "Epoch 5/25\n",
      "4888/4888 [==============================] - 24s 5ms/step - loss: 1.8773 - accuracy: 0.4447\n",
      "Epoch 6/25\n",
      "4888/4888 [==============================] - 24s 5ms/step - loss: 1.8003 - accuracy: 0.4639\n",
      "Epoch 7/25\n",
      "4888/4888 [==============================] - 23s 5ms/step - loss: 1.7362 - accuracy: 0.4815\n",
      "Epoch 8/25\n",
      "4888/4888 [==============================] - 23s 5ms/step - loss: 1.6841 - accuracy: 0.4970\n",
      "Epoch 9/25\n",
      "4888/4888 [==============================] - 24s 5ms/step - loss: 1.6403 - accuracy: 0.5082\n",
      "Epoch 10/25\n",
      "4888/4888 [==============================] - 24s 5ms/step - loss: 1.5995 - accuracy: 0.5177\n",
      "Epoch 11/25\n",
      "4888/4888 [==============================] - 26s 5ms/step - loss: 1.5660 - accuracy: 0.5287\n",
      "Epoch 12/25\n",
      "4888/4888 [==============================] - 24s 5ms/step - loss: 1.5362 - accuracy: 0.5363\n",
      "Epoch 13/25\n",
      "4888/4888 [==============================] - 23s 5ms/step - loss: 1.5061 - accuracy: 0.5454\n",
      "Epoch 14/25\n",
      "4888/4888 [==============================] - 23s 5ms/step - loss: 1.4802 - accuracy: 0.5514\n",
      "Epoch 15/25\n",
      "4888/4888 [==============================] - 23s 5ms/step - loss: 1.4573 - accuracy: 0.5576\n",
      "Epoch 16/25\n",
      "4888/4888 [==============================] - 25s 5ms/step - loss: 1.4352 - accuracy: 0.5635\n",
      "Epoch 17/25\n",
      "4888/4888 [==============================] - 24s 5ms/step - loss: 1.4164 - accuracy: 0.5691\n",
      "Epoch 18/25\n",
      "4888/4888 [==============================] - 24s 5ms/step - loss: 1.3954 - accuracy: 0.5759\n",
      "Epoch 19/25\n",
      "4888/4888 [==============================] - 24s 5ms/step - loss: 1.3770 - accuracy: 0.5783\n",
      "Epoch 20/25\n",
      "4888/4888 [==============================] - 24s 5ms/step - loss: 1.3627 - accuracy: 0.5823\n",
      "Epoch 21/25\n",
      "4888/4888 [==============================] - 23s 5ms/step - loss: 1.3456 - accuracy: 0.5866\n",
      "Epoch 22/25\n",
      "4888/4888 [==============================] - 24s 5ms/step - loss: 1.3290 - accuracy: 0.5911\n",
      "Epoch 23/25\n",
      "4888/4888 [==============================] - 24s 5ms/step - loss: 1.3165 - accuracy: 0.5977\n",
      "Epoch 24/25\n",
      "4888/4888 [==============================] - 23s 5ms/step - loss: 1.3035 - accuracy: 0.6002\n",
      "Epoch 25/25\n",
      "4888/4888 [==============================] - 24s 5ms/step - loss: 1.2896 - accuracy: 0.6026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28bebe42b90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CNN for top right quadrant\n",
    "\n",
    "# Define the input shape for each quadrant\n",
    "input_shape = (14, 14, 1)\n",
    "\n",
    "# Create a sequential model for the top left quadrant\n",
    "model_tr = Sequential()\n",
    "\n",
    "# Add a convolutional layer with 16 filters, 3x3 kernel size, and sigmoid activation\n",
    "model_tr.add(Conv2D(16, kernel_size=(3, 3), activation='sigmoid', input_shape=input_shape))\n",
    "\n",
    "# Add a max pooling layer with 2x2 pool size\n",
    "model_tr.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Add a convolutional layer with 32 filters, 3x3 kernel size, and sigmoid activation\n",
    "model_tr.add(Conv2D(32, kernel_size=(3, 3), activation='sigmoid'))\n",
    "\n",
    "# Add a max pooling layer with 2x2 pool size\n",
    "model_tr.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the output of the previous layer\n",
    "model_tr.add(Flatten())\n",
    "\n",
    "# Add a dense layer with 512 units and relu activation\n",
    "model_tr.add(Dense(512, activation='relu'))\n",
    "\n",
    "# Add the output layer with 46 units and softmax activation\n",
    "model_tr.add(Dense(46, activation='softmax'))\n",
    "\n",
    "# Compile the model with categorical crossentropy loss and Adam optimizer\n",
    "model_tr.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model_tr.summary()\n",
    "\n",
    "# Train the model on the top left quadrant dataset\n",
    "model_tr.fit(x_train_tr, train_labels_onehot, batch_size=16, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 12, 12, 16)        160       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 6, 6, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 4, 4, 32)          4640      \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 2, 2, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               66048     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 46)                23598     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 94,446\n",
      "Trainable params: 94,446\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "4888/4888 [==============================] - 15s 3ms/step - loss: 2.6112 - accuracy: 0.2760\n",
      "Epoch 2/25\n",
      "4888/4888 [==============================] - 22s 5ms/step - loss: 1.7198 - accuracy: 0.4781\n",
      "Epoch 3/25\n",
      "4888/4888 [==============================] - 23s 5ms/step - loss: 1.4700 - accuracy: 0.5465\n",
      "Epoch 4/25\n",
      "4888/4888 [==============================] - 24s 5ms/step - loss: 1.3187 - accuracy: 0.5882\n",
      "Epoch 5/25\n",
      "4888/4888 [==============================] - 25s 5ms/step - loss: 1.2122 - accuracy: 0.6174\n",
      "Epoch 6/25\n",
      "4888/4888 [==============================] - 25s 5ms/step - loss: 1.1337 - accuracy: 0.6406\n",
      "Epoch 7/25\n",
      "4888/4888 [==============================] - 25s 5ms/step - loss: 1.0705 - accuracy: 0.6595\n",
      "Epoch 8/25\n",
      "4888/4888 [==============================] - 25s 5ms/step - loss: 1.0220 - accuracy: 0.6725\n",
      "Epoch 9/25\n",
      "4888/4888 [==============================] - 26s 5ms/step - loss: 0.9805 - accuracy: 0.6838\n",
      "Epoch 10/25\n",
      "4888/4888 [==============================] - 32s 7ms/step - loss: 0.9431 - accuracy: 0.6952\n",
      "Epoch 11/25\n",
      "4888/4888 [==============================] - 35s 7ms/step - loss: 0.9135 - accuracy: 0.7013\n",
      "Epoch 12/25\n",
      "4888/4888 [==============================] - 26s 5ms/step - loss: 0.8855 - accuracy: 0.7111\n",
      "Epoch 13/25\n",
      "4888/4888 [==============================] - 24s 5ms/step - loss: 0.8589 - accuracy: 0.7196\n",
      "Epoch 14/25\n",
      "4888/4888 [==============================] - 24s 5ms/step - loss: 0.8384 - accuracy: 0.7244\n",
      "Epoch 15/25\n",
      "4888/4888 [==============================] - 24s 5ms/step - loss: 0.8180 - accuracy: 0.7324\n",
      "Epoch 16/25\n",
      "4888/4888 [==============================] - 24s 5ms/step - loss: 0.7986 - accuracy: 0.7377\n",
      "Epoch 17/25\n",
      "4888/4888 [==============================] - 24s 5ms/step - loss: 0.7799 - accuracy: 0.7421\n",
      "Epoch 18/25\n",
      "4888/4888 [==============================] - 23s 5ms/step - loss: 0.7650 - accuracy: 0.7470\n",
      "Epoch 19/25\n",
      "4888/4888 [==============================] - 24s 5ms/step - loss: 0.7506 - accuracy: 0.7516\n",
      "Epoch 20/25\n",
      "4888/4888 [==============================] - 24s 5ms/step - loss: 0.7363 - accuracy: 0.7567\n",
      "Epoch 21/25\n",
      "4888/4888 [==============================] - 24s 5ms/step - loss: 0.7235 - accuracy: 0.7601\n",
      "Epoch 22/25\n",
      "4888/4888 [==============================] - 24s 5ms/step - loss: 0.7145 - accuracy: 0.7612\n",
      "Epoch 23/25\n",
      "4888/4888 [==============================] - 24s 5ms/step - loss: 0.7020 - accuracy: 0.7659\n",
      "Epoch 24/25\n",
      "4888/4888 [==============================] - 24s 5ms/step - loss: 0.6887 - accuracy: 0.7699\n",
      "Epoch 25/25\n",
      "4888/4888 [==============================] - 24s 5ms/step - loss: 0.6784 - accuracy: 0.7726\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28b9757fb50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CNN for bottom left quadrant\n",
    "\n",
    "# Define the input shape for each quadrant\n",
    "input_shape = (14, 14, 1)\n",
    "\n",
    "# Create a sequential model for the top left quadrant\n",
    "model_bl = Sequential()\n",
    "\n",
    "# Add a convolutional layer with 16 filters, 3x3 kernel size, and sigmoid activation\n",
    "model_bl.add(Conv2D(16, kernel_size=(3, 3), activation='sigmoid', input_shape=input_shape))\n",
    "\n",
    "# Add a max pooling layer with 2x2 pool size\n",
    "model_bl.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Add a convolutional layer with 32 filters, 3x3 kernel size, and sigmoid activation\n",
    "model_bl.add(Conv2D(32, kernel_size=(3, 3), activation='sigmoid'))\n",
    "\n",
    "# Add a max pooling layer with 2x2 pool size\n",
    "model_bl.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the output of the previous layer\n",
    "model_bl.add(Flatten())\n",
    "\n",
    "# Add a dense layer with 512 units and relu activation\n",
    "model_bl.add(Dense(512, activation='relu'))\n",
    "\n",
    "# Add the output layer with 46 units and softmax activation\n",
    "model_bl.add(Dense(46, activation='softmax'))\n",
    "\n",
    "# Compile the model with categorical crossentropy loss and Adam optimizer\n",
    "model_bl.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model_bl.summary()\n",
    "\n",
    "# Train the model on the top left quadrant dataset\n",
    "model_bl.fit(x_train_bl, train_labels_onehot, batch_size=16, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 12, 12, 16)        160       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 6, 6, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 4, 4, 32)          4640      \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 2, 2, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 512)               66048     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 46)                23598     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 94,446\n",
      "Trainable params: 94,446\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "4888/4888 [==============================] - 14s 3ms/step - loss: 2.8327 - accuracy: 0.2131\n",
      "Epoch 2/25\n",
      "4888/4888 [==============================] - 17s 4ms/step - loss: 2.0652 - accuracy: 0.3745\n",
      "Epoch 3/25\n",
      "4888/4888 [==============================] - 20s 4ms/step - loss: 1.8489 - accuracy: 0.4282\n",
      "Epoch 4/25\n",
      "4888/4888 [==============================] - 19s 4ms/step - loss: 1.7205 - accuracy: 0.4611\n",
      "Epoch 5/25\n",
      "4888/4888 [==============================] - 20s 4ms/step - loss: 1.6307 - accuracy: 0.4875\n",
      "Epoch 6/25\n",
      "4888/4888 [==============================] - 21s 4ms/step - loss: 1.5561 - accuracy: 0.5080\n",
      "Epoch 7/25\n",
      "4888/4888 [==============================] - 22s 4ms/step - loss: 1.4979 - accuracy: 0.5234\n",
      "Epoch 8/25\n",
      "4888/4888 [==============================] - 23s 5ms/step - loss: 1.4498 - accuracy: 0.5391\n",
      "Epoch 9/25\n",
      "4888/4888 [==============================] - 23s 5ms/step - loss: 1.4087 - accuracy: 0.5504\n",
      "Epoch 10/25\n",
      "4888/4888 [==============================] - 23s 5ms/step - loss: 1.3752 - accuracy: 0.5596\n",
      "Epoch 11/25\n",
      "4888/4888 [==============================] - 24s 5ms/step - loss: 1.3453 - accuracy: 0.5690\n",
      "Epoch 12/25\n",
      "4888/4888 [==============================] - 25s 5ms/step - loss: 1.3199 - accuracy: 0.5778\n",
      "Epoch 13/25\n",
      "4888/4888 [==============================] - 24s 5ms/step - loss: 1.2970 - accuracy: 0.5822\n",
      "Epoch 14/25\n",
      "4888/4888 [==============================] - 24s 5ms/step - loss: 1.2738 - accuracy: 0.5906\n",
      "Epoch 15/25\n",
      "4888/4888 [==============================] - 24s 5ms/step - loss: 1.2542 - accuracy: 0.5966\n",
      "Epoch 16/25\n",
      "4888/4888 [==============================] - 25s 5ms/step - loss: 1.2377 - accuracy: 0.6012\n",
      "Epoch 17/25\n",
      "4888/4888 [==============================] - 24s 5ms/step - loss: 1.2206 - accuracy: 0.6075\n",
      "Epoch 18/25\n",
      "4888/4888 [==============================] - 24s 5ms/step - loss: 1.2050 - accuracy: 0.6105\n",
      "Epoch 19/25\n",
      "4888/4888 [==============================] - 24s 5ms/step - loss: 1.1895 - accuracy: 0.6144\n",
      "Epoch 20/25\n",
      "4888/4888 [==============================] - 24s 5ms/step - loss: 1.1749 - accuracy: 0.6202\n",
      "Epoch 21/25\n",
      "4888/4888 [==============================] - 23s 5ms/step - loss: 1.1648 - accuracy: 0.6240\n",
      "Epoch 22/25\n",
      "4888/4888 [==============================] - 23s 5ms/step - loss: 1.1516 - accuracy: 0.6277\n",
      "Epoch 23/25\n",
      "4888/4888 [==============================] - 23s 5ms/step - loss: 1.1416 - accuracy: 0.6311\n",
      "Epoch 24/25\n",
      "4888/4888 [==============================] - 24s 5ms/step - loss: 1.1284 - accuracy: 0.6357\n",
      "Epoch 25/25\n",
      "4888/4888 [==============================] - 23s 5ms/step - loss: 1.1183 - accuracy: 0.6374\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28b98cb5d90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CNN for bottom right quadrant\n",
    "\n",
    "# Define the input shape for each quadrant\n",
    "input_shape = (14, 14, 1)\n",
    "\n",
    "# Create a sequential model for the top left quadrant\n",
    "model_br = Sequential()\n",
    "\n",
    "# Add a convolutional layer with 16 filters, 3x3 kernel size, and sigmoid activation\n",
    "model_br.add(Conv2D(16, kernel_size=(3, 3), activation='sigmoid', input_shape=input_shape))\n",
    "\n",
    "# Add a max pooling layer with 2x2 pool size\n",
    "model_br.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Add a convolutional layer with 32 filters, 3x3 kernel size, and sigmoid activation\n",
    "model_br.add(Conv2D(32, kernel_size=(3, 3), activation='sigmoid'))\n",
    "\n",
    "# Add a max pooling layer with 2x2 pool size\n",
    "model_br.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the output of the previous layer\n",
    "model_br.add(Flatten())\n",
    "\n",
    "# Add a dense layer with 512 units and relu activation\n",
    "model_br.add(Dense(512, activation='relu'))\n",
    "\n",
    "# Add the output layer with 46 units and softmax activation\n",
    "model_br.add(Dense(46, activation='softmax'))\n",
    "\n",
    "# Compile the model with categorical crossentropy loss and Adam optimizer\n",
    "model_br.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model_br.summary()\n",
    "\n",
    "# Train the model on the top left quadrant dataset\n",
    "model_br.fit(x_train_br, train_labels_onehot, batch_size=16, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 12, 12, 16)        160       \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 6, 6, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 4, 4, 32)          4640      \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 2, 2, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 512)               66048     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 46)                23598     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 94,446\n",
      "Trainable params: 94,446\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "4888/4888 [==============================] - 21s 4ms/step - loss: 2.6885 - accuracy: 0.2685\n",
      "Epoch 2/25\n",
      "4888/4888 [==============================] - 23s 5ms/step - loss: 1.7003 - accuracy: 0.4995\n",
      "Epoch 3/25\n",
      "4888/4888 [==============================] - 24s 5ms/step - loss: 1.3807 - accuracy: 0.5859\n",
      "Epoch 4/25\n",
      "4888/4888 [==============================] - 23s 5ms/step - loss: 1.1959 - accuracy: 0.6347\n",
      "Epoch 5/25\n",
      "4888/4888 [==============================] - 23s 5ms/step - loss: 1.0661 - accuracy: 0.6704\n",
      "Epoch 6/25\n",
      "4888/4888 [==============================] - 24s 5ms/step - loss: 0.9745 - accuracy: 0.6951\n",
      "Epoch 7/25\n",
      "4888/4888 [==============================] - 23s 5ms/step - loss: 0.9025 - accuracy: 0.7156\n",
      "Epoch 8/25\n",
      "4888/4888 [==============================] - 24s 5ms/step - loss: 0.8438 - accuracy: 0.7304\n",
      "Epoch 9/25\n",
      "4888/4888 [==============================] - 23s 5ms/step - loss: 0.7972 - accuracy: 0.7449\n",
      "Epoch 10/25\n",
      "4888/4888 [==============================] - 25s 5ms/step - loss: 0.7542 - accuracy: 0.7577\n",
      "Epoch 11/25\n",
      "4888/4888 [==============================] - 25s 5ms/step - loss: 0.7179 - accuracy: 0.7684\n",
      "Epoch 12/25\n",
      "4888/4888 [==============================] - 25s 5ms/step - loss: 0.6885 - accuracy: 0.7771\n",
      "Epoch 13/25\n",
      "4888/4888 [==============================] - 25s 5ms/step - loss: 0.6625 - accuracy: 0.7850\n",
      "Epoch 14/25\n",
      "4888/4888 [==============================] - 24s 5ms/step - loss: 0.6386 - accuracy: 0.7921\n",
      "Epoch 15/25\n",
      "4888/4888 [==============================] - 25s 5ms/step - loss: 0.6149 - accuracy: 0.7987\n",
      "Epoch 16/25\n",
      "4888/4888 [==============================] - 24s 5ms/step - loss: 0.5944 - accuracy: 0.8055\n",
      "Epoch 17/25\n",
      "4888/4888 [==============================] - 25s 5ms/step - loss: 0.5768 - accuracy: 0.8101\n",
      "Epoch 18/25\n",
      "4888/4888 [==============================] - 26s 5ms/step - loss: 0.5618 - accuracy: 0.8152\n",
      "Epoch 19/25\n",
      "4888/4888 [==============================] - 24s 5ms/step - loss: 0.5474 - accuracy: 0.8191\n",
      "Epoch 20/25\n",
      "4888/4888 [==============================] - 24s 5ms/step - loss: 0.5317 - accuracy: 0.8229\n",
      "Epoch 21/25\n",
      "4888/4888 [==============================] - 23s 5ms/step - loss: 0.5189 - accuracy: 0.8276\n",
      "Epoch 22/25\n",
      "4888/4888 [==============================] - 25s 5ms/step - loss: 0.5056 - accuracy: 0.8308\n",
      "Epoch 23/25\n",
      "4888/4888 [==============================] - 23s 5ms/step - loss: 0.4928 - accuracy: 0.8348\n",
      "Epoch 24/25\n",
      "4888/4888 [==============================] - 24s 5ms/step - loss: 0.4834 - accuracy: 0.8385\n",
      "Epoch 25/25\n",
      "4888/4888 [==============================] - 24s 5ms/step - loss: 0.4737 - accuracy: 0.8412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28b9763cc10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CNN for center quadrant\n",
    "\n",
    "# Define the input shape for each quadrant\n",
    "input_shape = (14, 14, 1)\n",
    "\n",
    "# Create a sequential model for the top left quadrant\n",
    "model_c = Sequential()\n",
    "\n",
    "# Add a convolutional layer with 16 filters, 3x3 kernel size, and sigmoid activation\n",
    "model_c.add(Conv2D(16, kernel_size=(3, 3), activation='sigmoid', input_shape=input_shape))\n",
    "\n",
    "# Add a max pooling layer with 2x2 pool size\n",
    "model_c.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Add a convolutional layer with 32 filters, 3x3 kernel size, and sigmoid activation\n",
    "model_c.add(Conv2D(32, kernel_size=(3, 3), activation='sigmoid'))\n",
    "\n",
    "# Add a max pooling layer with 2x2 pool size\n",
    "model_c.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the output of the previous layer\n",
    "model_c.add(Flatten())\n",
    "\n",
    "# Add a dense layer with 512 units and relu activation\n",
    "model_c.add(Dense(512, activation='relu'))\n",
    "\n",
    "# Add the output layer with 46 units and softmax activation\n",
    "model_c.add(Dense(46, activation='softmax'))\n",
    "\n",
    "# Compile the model with categorical crossentropy loss and Adam optimizer\n",
    "model_c.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model_c.summary()\n",
    "\n",
    "# Train the model on the top left quadrant dataset\n",
    "model_c.fit(x_train_c, train_labels_onehot, batch_size=16, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2444/2444 [==============================] - 4s 2ms/step\n",
      "2444/2444 [==============================] - 4s 2ms/step\n",
      "2444/2444 [==============================] - 6s 3ms/step\n",
      "2444/2444 [==============================] - 7s 3ms/step\n",
      "2444/2444 [==============================] - 6s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# create new models to extract features from the last dense layer\n",
    "model_tl_features = Model(inputs=model_tl.input, outputs=model_tl.get_layer('dense').output)\n",
    "model_tr_features = Model(inputs=model_tr.input, outputs=model_tr.get_layer('dense_2').output)\n",
    "model_bl_features = Model(inputs=model_bl.input, outputs=model_bl.get_layer('dense_4').output)\n",
    "model_br_features = Model(inputs=model_br.input, outputs=model_br.get_layer('dense_6').output)\n",
    "model_c_features = Model(inputs=model_c.input, outputs=model_c.get_layer('dense_8').output)\n",
    "\n",
    "# extract features from the last dense layer for each quadrant\n",
    "tl_features = model_tl_features.predict(x_train_tl)\n",
    "tr_features = model_tr_features.predict(x_train_tr)\n",
    "bl_features = model_bl_features.predict(x_train_bl)\n",
    "br_features = model_br_features.predict(x_train_br)\n",
    "center_features = model_c_features.predict(x_train_c)\n",
    "\n",
    "# concatenate the features from all 5 quadrants into a single input\n",
    "features = np.concatenate((tl_features, tr_features, bl_features, br_features, center_features), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4888/4888 [==============================] - 725s 148ms/step - loss: 0.3858 - accuracy: 0.9015\n",
      "Epoch 2/10\n",
      "4888/4888 [==============================] - 721s 147ms/step - loss: 0.1772 - accuracy: 0.9609\n",
      "Epoch 3/10\n",
      "4888/4888 [==============================] - 722s 148ms/step - loss: 0.1378 - accuracy: 0.9721\n",
      "Epoch 4/10\n",
      "4888/4888 [==============================] - 719s 147ms/step - loss: 0.1272 - accuracy: 0.9760\n",
      "Epoch 5/10\n",
      "4888/4888 [==============================] - 719s 147ms/step - loss: 0.1026 - accuracy: 0.9800\n",
      "Epoch 6/10\n",
      "4888/4888 [==============================] - 720s 147ms/step - loss: 0.1040 - accuracy: 0.9824\n",
      "Epoch 7/10\n",
      "4888/4888 [==============================] - 715s 146ms/step - loss: 0.0885 - accuracy: 0.9851\n",
      "Epoch 8/10\n",
      "4888/4888 [==============================] - 704s 144ms/step - loss: 0.0932 - accuracy: 0.9858\n",
      "Epoch 9/10\n",
      "4888/4888 [==============================] - 707s 145ms/step - loss: 0.0797 - accuracy: 0.9877\n",
      "Epoch 10/10\n",
      "4888/4888 [==============================] - 711s 145ms/step - loss: 0.0834 - accuracy: 0.9878\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# define the DNN classifier model\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(2560, activation='relu', input_shape=(features.shape[1],)))\n",
    "classifier.add(Dense(1000, activation='relu'))\n",
    "classifier.add(Dense(1000, activation='relu'))\n",
    "classifier.add(Dense(1000, activation='relu'))\n",
    "classifier.add(Dense(46, activation='softmax'))\n",
    "\n",
    "# compile the model\n",
    "classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = classifier.fit(features, train_labels_onehot, batch_size=16, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the test data for prediction and testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels_int = label_encoder.fit_transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the integer labels to one-hot encoding\n",
    "test_labels_onehot = to_categorical(test_labels_int, num_classes=46)\n",
    "\n",
    "# Split the data into the five quadrants\n",
    "x_test_tl = test_images[:,:14,:14].reshape(-1, 14, 14, 1)\n",
    "x_test_tr = test_images[:,:14,14:].reshape(-1, 14, 14, 1)\n",
    "x_test_bl = test_images[:,14:,:14].reshape(-1, 14, 14, 1)\n",
    "x_test_br = test_images[:,14:,14:].reshape(-1, 14, 14, 1)\n",
    "x_test_c = test_images[:,7:21,7:21].reshape(-1, 14, 14, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432/432 [==============================] - 1s 1ms/step\n",
      "432/432 [==============================] - 1s 2ms/step\n",
      "432/432 [==============================] - 1s 1ms/step\n",
      "432/432 [==============================] - 1s 1ms/step\n",
      "432/432 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# extract features from the last dense layer for each quadrant\n",
    "tl_features_test = model_tl_features.predict(x_test_tl)\n",
    "tr_features_test = model_tr_features.predict(x_test_tr)\n",
    "bl_features_test = model_bl_features.predict(x_test_bl)\n",
    "br_features_test = model_br_features.predict(x_test_br)\n",
    "center_features_test = model_c_features.predict(x_test_c)\n",
    "\n",
    "# concatenate the features from all 5 quadrants into a single input\n",
    "features_test = np.concatenate((tl_features_test, tr_features_test, bl_features_test, br_features_test, center_features_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to disk\n",
    "classifier.save(\"model_f512_b16e25_b32e10.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432/432 [==============================] - 7s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "test_predictions = classifier.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "accuracy = accuracy_score(test_labels_int, test_predictions.argmax(axis=1))\n",
    "precision = precision_score(test_labels_int, test_predictions.argmax(axis=1), average='weighted')\n",
    "recall = recall_score(test_labels_int, test_predictions.argmax(axis=1), average='weighted')\n",
    "f1 = f1_score(test_labels_int, test_predictions.argmax(axis=1), average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9610869565217391\n",
      "Precision: 0.9631139063878587\n",
      "Recall: 0.9610869565217391\n",
      "F1 Score: 0.9611537659911858\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', accuracy)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1 Score:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
