{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the train and test folders\n",
    "train_path = 'C:/A/code/VSC/python/test/cropped_DevanagariHandwrittenCharacterDataset/Train/'\n",
    "test_path = 'C:/A/code/VSC/python/test/cropped_DevanagariHandwrittenCharacterDataset/Test/'\n",
    "\n",
    "# Define a function to load and preprocess the images\n",
    "def load_images(path):\n",
    "    # Create empty lists to store the images and labels\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    # Loop through each folder (which represents a class) in the path\n",
    "    for folder in os.listdir(path):\n",
    "        # Get the path to the folder\n",
    "        folder_path = os.path.join(path, folder)\n",
    "        # Loop through each image in the folder\n",
    "        for file in os.listdir(folder_path):\n",
    "            # Get the path to the image file\n",
    "            img_path = os.path.join(folder_path, file)\n",
    "            # Load the image using OpenCV\n",
    "            img = cv2.imread(img_path)\n",
    "            # Convert the image to grayscale\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            # Normalize the pixel values of the images\n",
    "            img = img.astype('float32') / 255.0\n",
    "            # Append the image to the images list\n",
    "            images.append(img)\n",
    "            # Append the label to the labels list\n",
    "            labels.append(folder)\n",
    "\n",
    "    # Convert the images and labels lists to NumPy arrays\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    # Return the images and labels arrays\n",
    "    return images, labels\n",
    "\n",
    "# Load the train images and labels\n",
    "train_images, train_labels = load_images(train_path)\n",
    "\n",
    "# Load the test images and labels\n",
    "test_images, test_labels = load_images(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Convert the string labels to integer labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_int = label_encoder.fit_transform(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the integer labels to one-hot encoding\n",
    "train_labels_onehot = to_categorical(train_labels_int, num_classes=46)\n",
    "\n",
    "# Split the data into the five quadrants\n",
    "x_train_tl = train_images[:,:14,:14].reshape(-1, 14, 14, 1)\n",
    "x_train_tr = train_images[:,:14,14:].reshape(-1, 14, 14, 1)\n",
    "x_train_bl = train_images[:,14:,:14].reshape(-1, 14, 14, 1)\n",
    "x_train_br = train_images[:,14:,14:].reshape(-1, 14, 14, 1)\n",
    "x_train_c = train_images[:,7:21,7:21].reshape(-1, 14, 14, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 12, 12, 16)        160       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 6, 6, 16)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 4, 4, 32)          4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 2, 2, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               66048     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 46)                23598     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 94,446\n",
      "Trainable params: 94,446\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "2444/2444 [==============================] - 10s 4ms/step - loss: 2.9963 - accuracy: 0.1873\n",
      "Epoch 2/25\n",
      "2444/2444 [==============================] - 9s 4ms/step - loss: 2.1369 - accuracy: 0.3724\n",
      "Epoch 3/25\n",
      "2444/2444 [==============================] - 11s 5ms/step - loss: 1.8762 - accuracy: 0.4399\n",
      "Epoch 4/25\n",
      "2444/2444 [==============================] - 11s 5ms/step - loss: 1.7110 - accuracy: 0.4842\n",
      "Epoch 5/25\n",
      "2444/2444 [==============================] - 11s 5ms/step - loss: 1.5967 - accuracy: 0.5145\n",
      "Epoch 6/25\n",
      "2444/2444 [==============================] - 11s 5ms/step - loss: 1.5087 - accuracy: 0.5386\n",
      "Epoch 7/25\n",
      "2444/2444 [==============================] - 11s 5ms/step - loss: 1.4366 - accuracy: 0.5582\n",
      "Epoch 8/25\n",
      "2444/2444 [==============================] - 12s 5ms/step - loss: 1.3720 - accuracy: 0.5756\n",
      "Epoch 9/25\n",
      "2444/2444 [==============================] - 12s 5ms/step - loss: 1.3204 - accuracy: 0.5898\n",
      "Epoch 10/25\n",
      "2444/2444 [==============================] - 12s 5ms/step - loss: 1.2748 - accuracy: 0.6034\n",
      "Epoch 11/25\n",
      "2444/2444 [==============================] - 13s 5ms/step - loss: 1.2337 - accuracy: 0.6135\n",
      "Epoch 12/25\n",
      "2444/2444 [==============================] - 12s 5ms/step - loss: 1.1989 - accuracy: 0.6237\n",
      "Epoch 13/25\n",
      "2444/2444 [==============================] - 13s 5ms/step - loss: 1.1662 - accuracy: 0.6346\n",
      "Epoch 14/25\n",
      "2444/2444 [==============================] - 13s 5ms/step - loss: 1.1391 - accuracy: 0.6393\n",
      "Epoch 15/25\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 1.1126 - accuracy: 0.6476\n",
      "Epoch 16/25\n",
      "2444/2444 [==============================] - 14s 6ms/step - loss: 1.0893 - accuracy: 0.6539\n",
      "Epoch 17/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0684 - accuracy: 0.6615\n",
      "Epoch 18/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0495 - accuracy: 0.6663\n",
      "Epoch 19/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0310 - accuracy: 0.6705\n",
      "Epoch 20/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0132 - accuracy: 0.6762\n",
      "Epoch 21/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9975 - accuracy: 0.6810\n",
      "Epoch 22/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9836 - accuracy: 0.6834\n",
      "Epoch 23/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9692 - accuracy: 0.6880\n",
      "Epoch 24/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9561 - accuracy: 0.6931\n",
      "Epoch 25/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9434 - accuracy: 0.6960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ca4daba950>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CNN for top left quadrant\n",
    "\n",
    "# Define the input shape for each quadrant\n",
    "input_shape = (14, 14, 1)\n",
    "\n",
    "# Create a sequential model for the top left quadrant\n",
    "model_tl = Sequential()\n",
    "\n",
    "# Add a convolutional layer with 16 filters, 3x3 kernel size, and sigmoid activation\n",
    "model_tl.add(Conv2D(16, kernel_size=(3, 3), activation='sigmoid', input_shape=input_shape))\n",
    "\n",
    "# Add a max pooling layer with 2x2 pool size\n",
    "model_tl.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Add a convolutional layer with 32 filters, 3x3 kernel size, and sigmoid activation\n",
    "model_tl.add(Conv2D(32, kernel_size=(3, 3), activation='sigmoid'))\n",
    "\n",
    "# Add a max pooling layer with 2x2 pool size\n",
    "model_tl.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the output of the previous layer\n",
    "model_tl.add(Flatten())\n",
    "\n",
    "# Add a dense layer with 512 units and relu activation\n",
    "model_tl.add(Dense(512, activation='relu'))\n",
    "\n",
    "# Add the output layer with 46 units and softmax activation\n",
    "model_tl.add(Dense(46, activation='softmax'))\n",
    "\n",
    "# Compile the model with categorical crossentropy loss and Adam optimizer\n",
    "model_tl.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model_tl.summary()\n",
    "\n",
    "# Train the model on the top left quadrant dataset\n",
    "model_tl.fit(x_train_tl, train_labels_onehot, batch_size=32, epochs=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 12, 12, 16)        160       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 4, 4, 32)          4640      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 2, 2, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               66048     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 46)                23598     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 94,446\n",
      "Trainable params: 94,446\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 3.2640 - accuracy: 0.1381\n",
      "Epoch 2/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 2.5199 - accuracy: 0.2851\n",
      "Epoch 3/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 2.2542 - accuracy: 0.3511\n",
      "Epoch 4/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 2.0837 - accuracy: 0.3911\n",
      "Epoch 5/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.9640 - accuracy: 0.4229\n",
      "Epoch 6/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.8731 - accuracy: 0.4458\n",
      "Epoch 7/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.8040 - accuracy: 0.4652\n",
      "Epoch 8/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.7438 - accuracy: 0.4801\n",
      "Epoch 9/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.6932 - accuracy: 0.4931\n",
      "Epoch 10/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.6515 - accuracy: 0.5028\n",
      "Epoch 11/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.6117 - accuracy: 0.5147\n",
      "Epoch 12/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.5791 - accuracy: 0.5235\n",
      "Epoch 13/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.5467 - accuracy: 0.5324\n",
      "Epoch 14/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.5200 - accuracy: 0.5415\n",
      "Epoch 15/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.4953 - accuracy: 0.5462\n",
      "Epoch 16/25\n",
      "2444/2444 [==============================] - 16s 6ms/step - loss: 1.4713 - accuracy: 0.5539\n",
      "Epoch 17/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.4486 - accuracy: 0.5598\n",
      "Epoch 18/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.4287 - accuracy: 0.5642\n",
      "Epoch 19/25\n",
      "2444/2444 [==============================] - 16s 6ms/step - loss: 1.4086 - accuracy: 0.5702\n",
      "Epoch 20/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.3913 - accuracy: 0.5754\n",
      "Epoch 21/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.3758 - accuracy: 0.5791\n",
      "Epoch 22/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.3591 - accuracy: 0.5846\n",
      "Epoch 23/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.3447 - accuracy: 0.5879\n",
      "Epoch 24/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.3291 - accuracy: 0.5927\n",
      "Epoch 25/25\n",
      "2444/2444 [==============================] - 16s 7ms/step - loss: 1.3158 - accuracy: 0.5966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ca4faadb50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CNN for top right quadrant\n",
    "\n",
    "# Define the input shape for each quadrant\n",
    "input_shape = (14, 14, 1)\n",
    "\n",
    "# Create a sequential model for the top left quadrant\n",
    "model_tr = Sequential()\n",
    "\n",
    "# Add a convolutional layer with 16 filters, 3x3 kernel size, and sigmoid activation\n",
    "model_tr.add(Conv2D(16, kernel_size=(3, 3), activation='sigmoid', input_shape=input_shape))\n",
    "\n",
    "# Add a max pooling layer with 2x2 pool size\n",
    "model_tr.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Add a convolutional layer with 32 filters, 3x3 kernel size, and sigmoid activation\n",
    "model_tr.add(Conv2D(32, kernel_size=(3, 3), activation='sigmoid'))\n",
    "\n",
    "# Add a max pooling layer with 2x2 pool size\n",
    "model_tr.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the output of the previous layer\n",
    "model_tr.add(Flatten())\n",
    "\n",
    "# Add a dense layer with 512 units and relu activation\n",
    "model_tr.add(Dense(512, activation='relu'))\n",
    "\n",
    "# Add the output layer with 46 units and softmax activation\n",
    "model_tr.add(Dense(46, activation='softmax'))\n",
    "\n",
    "# Compile the model with categorical crossentropy loss and Adam optimizer\n",
    "model_tr.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model_tr.summary()\n",
    "\n",
    "# Train the model on the top left quadrant dataset\n",
    "model_tr.fit(x_train_tr, train_labels_onehot, batch_size=32, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 12, 12, 16)        160       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 6, 6, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 4, 4, 32)          4640      \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 2, 2, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               66048     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 46)                23598     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 94,446\n",
      "Trainable params: 94,446\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "2444/2444 [==============================] - 12s 5ms/step - loss: 2.8820 - accuracy: 0.2242\n",
      "Epoch 2/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.8524 - accuracy: 0.4467\n",
      "Epoch 3/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.5803 - accuracy: 0.5168\n",
      "Epoch 4/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.4255 - accuracy: 0.5578\n",
      "Epoch 5/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.3169 - accuracy: 0.5891\n",
      "Epoch 6/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.2371 - accuracy: 0.6126\n",
      "Epoch 7/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.1724 - accuracy: 0.6296\n",
      "Epoch 8/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.1201 - accuracy: 0.6457\n",
      "Epoch 9/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0773 - accuracy: 0.6567\n",
      "Epoch 10/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0383 - accuracy: 0.6678\n",
      "Epoch 11/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0037 - accuracy: 0.6778\n",
      "Epoch 12/25\n",
      "2444/2444 [==============================] - 16s 6ms/step - loss: 0.9744 - accuracy: 0.6860\n",
      "Epoch 13/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9455 - accuracy: 0.6955\n",
      "Epoch 14/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9195 - accuracy: 0.7017\n",
      "Epoch 15/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8991 - accuracy: 0.7094\n",
      "Epoch 16/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8759 - accuracy: 0.7167\n",
      "Epoch 17/25\n",
      "2444/2444 [==============================] - 17s 7ms/step - loss: 0.8562 - accuracy: 0.7201\n",
      "Epoch 18/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8392 - accuracy: 0.7277\n",
      "Epoch 19/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8219 - accuracy: 0.7326\n",
      "Epoch 20/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8069 - accuracy: 0.7365\n",
      "Epoch 21/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7932 - accuracy: 0.7405\n",
      "Epoch 22/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7791 - accuracy: 0.7453\n",
      "Epoch 23/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7654 - accuracy: 0.7488\n",
      "Epoch 24/25\n",
      "2444/2444 [==============================] - 16s 7ms/step - loss: 0.7548 - accuracy: 0.7516\n",
      "Epoch 25/25\n",
      "2444/2444 [==============================] - 16s 6ms/step - loss: 0.7435 - accuracy: 0.7554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ca766ebcd0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CNN for bottom left quadrant\n",
    "\n",
    "# Define the input shape for each quadrant\n",
    "input_shape = (14, 14, 1)\n",
    "\n",
    "# Create a sequential model for the top left quadrant\n",
    "model_bl = Sequential()\n",
    "\n",
    "# Add a convolutional layer with 16 filters, 3x3 kernel size, and sigmoid activation\n",
    "model_bl.add(Conv2D(16, kernel_size=(3, 3), activation='sigmoid', input_shape=input_shape))\n",
    "\n",
    "# Add a max pooling layer with 2x2 pool size\n",
    "model_bl.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Add a convolutional layer with 32 filters, 3x3 kernel size, and sigmoid activation\n",
    "model_bl.add(Conv2D(32, kernel_size=(3, 3), activation='sigmoid'))\n",
    "\n",
    "# Add a max pooling layer with 2x2 pool size\n",
    "model_bl.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the output of the previous layer\n",
    "model_bl.add(Flatten())\n",
    "\n",
    "# Add a dense layer with 512 units and relu activation\n",
    "model_bl.add(Dense(512, activation='relu'))\n",
    "\n",
    "# Add the output layer with 46 units and softmax activation\n",
    "model_bl.add(Dense(46, activation='softmax'))\n",
    "\n",
    "# Compile the model with categorical crossentropy loss and Adam optimizer\n",
    "model_bl.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model_bl.summary()\n",
    "\n",
    "# Train the model on the top left quadrant dataset\n",
    "model_bl.fit(x_train_bl, train_labels_onehot, batch_size=32, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 12, 12, 16)        160       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 6, 6, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 4, 4, 32)          4640      \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 2, 2, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 512)               66048     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 46)                23598     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 94,446\n",
      "Trainable params: 94,446\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "2444/2444 [==============================] - 10s 4ms/step - loss: 3.0524 - accuracy: 0.1710\n",
      "Epoch 2/25\n",
      "2444/2444 [==============================] - 16s 7ms/step - loss: 2.1893 - accuracy: 0.3450\n",
      "Epoch 3/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.9579 - accuracy: 0.4008\n",
      "Epoch 4/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.8246 - accuracy: 0.4355\n",
      "Epoch 5/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.7286 - accuracy: 0.4619\n",
      "Epoch 6/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.6575 - accuracy: 0.4806\n",
      "Epoch 7/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.5977 - accuracy: 0.4979\n",
      "Epoch 8/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.5453 - accuracy: 0.5124\n",
      "Epoch 9/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.4995 - accuracy: 0.5249\n",
      "Epoch 10/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.4607 - accuracy: 0.5360\n",
      "Epoch 11/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.4245 - accuracy: 0.5460\n",
      "Epoch 12/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.3958 - accuracy: 0.5554\n",
      "Epoch 13/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.3682 - accuracy: 0.5620\n",
      "Epoch 14/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.3452 - accuracy: 0.5675\n",
      "Epoch 15/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.3209 - accuracy: 0.5766\n",
      "Epoch 16/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.2992 - accuracy: 0.5846\n",
      "Epoch 17/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.2823 - accuracy: 0.5892\n",
      "Epoch 18/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.2640 - accuracy: 0.5932\n",
      "Epoch 19/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.2479 - accuracy: 0.5998\n",
      "Epoch 20/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.2332 - accuracy: 0.6034\n",
      "Epoch 21/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.2179 - accuracy: 0.6077\n",
      "Epoch 22/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.2041 - accuracy: 0.6129\n",
      "Epoch 23/25\n",
      "2444/2444 [==============================] - 16s 6ms/step - loss: 1.1920 - accuracy: 0.6167\n",
      "Epoch 24/25\n",
      "2444/2444 [==============================] - 16s 6ms/step - loss: 1.1812 - accuracy: 0.6181\n",
      "Epoch 25/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.1665 - accuracy: 0.6246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ca77277fd0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CNN for bottom right quadrant\n",
    "\n",
    "# Define the input shape for each quadrant\n",
    "input_shape = (14, 14, 1)\n",
    "\n",
    "# Create a sequential model for the top left quadrant\n",
    "model_br = Sequential()\n",
    "\n",
    "# Add a convolutional layer with 16 filters, 3x3 kernel size, and sigmoid activation\n",
    "model_br.add(Conv2D(16, kernel_size=(3, 3), activation='sigmoid', input_shape=input_shape))\n",
    "\n",
    "# Add a max pooling layer with 2x2 pool size\n",
    "model_br.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Add a convolutional layer with 32 filters, 3x3 kernel size, and sigmoid activation\n",
    "model_br.add(Conv2D(32, kernel_size=(3, 3), activation='sigmoid'))\n",
    "\n",
    "# Add a max pooling layer with 2x2 pool size\n",
    "model_br.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the output of the previous layer\n",
    "model_br.add(Flatten())\n",
    "\n",
    "# Add a dense layer with 512 units and relu activation\n",
    "model_br.add(Dense(512, activation='relu'))\n",
    "\n",
    "# Add the output layer with 46 units and softmax activation\n",
    "model_br.add(Dense(46, activation='softmax'))\n",
    "\n",
    "# Compile the model with categorical crossentropy loss and Adam optimizer\n",
    "model_br.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model_br.summary()\n",
    "\n",
    "# Train the model on the top left quadrant dataset\n",
    "model_br.fit(x_train_br, train_labels_onehot, batch_size=32, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 12, 12, 16)        160       \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 6, 6, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 4, 4, 32)          4640      \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 2, 2, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 512)               66048     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 46)                23598     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 94,446\n",
      "Trainable params: 94,446\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "2444/2444 [==============================] - 9s 4ms/step - loss: 2.9660 - accuracy: 0.2076\n",
      "Epoch 2/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.8897 - accuracy: 0.4545\n",
      "Epoch 3/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.5363 - accuracy: 0.5446\n",
      "Epoch 4/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.3352 - accuracy: 0.6003\n",
      "Epoch 5/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.2016 - accuracy: 0.6348\n",
      "Epoch 6/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.1043 - accuracy: 0.6604\n",
      "Epoch 7/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 1.0297 - accuracy: 0.6822\n",
      "Epoch 8/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9675 - accuracy: 0.6989\n",
      "Epoch 9/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.9173 - accuracy: 0.7134\n",
      "Epoch 10/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8737 - accuracy: 0.7249\n",
      "Epoch 11/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.8373 - accuracy: 0.7354\n",
      "Epoch 12/25\n",
      "2444/2444 [==============================] - 18s 7ms/step - loss: 0.8047 - accuracy: 0.7446\n",
      "Epoch 13/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7757 - accuracy: 0.7526\n",
      "Epoch 14/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7479 - accuracy: 0.7609\n",
      "Epoch 15/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7246 - accuracy: 0.7675\n",
      "Epoch 16/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.7040 - accuracy: 0.7732\n",
      "Epoch 17/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.6841 - accuracy: 0.7782\n",
      "Epoch 18/25\n",
      "2444/2444 [==============================] - 16s 7ms/step - loss: 0.6661 - accuracy: 0.7842\n",
      "Epoch 19/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.6475 - accuracy: 0.7908\n",
      "Epoch 20/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.6329 - accuracy: 0.7941\n",
      "Epoch 21/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.6162 - accuracy: 0.7995\n",
      "Epoch 22/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.6044 - accuracy: 0.8036\n",
      "Epoch 23/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.5909 - accuracy: 0.8071\n",
      "Epoch 24/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.5784 - accuracy: 0.8110\n",
      "Epoch 25/25\n",
      "2444/2444 [==============================] - 15s 6ms/step - loss: 0.5660 - accuracy: 0.8138\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ca7b987fd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CNN for center quadrant\n",
    "\n",
    "# Define the input shape for each quadrant\n",
    "input_shape = (14, 14, 1)\n",
    "\n",
    "# Create a sequential model for the top left quadrant\n",
    "model_c = Sequential()\n",
    "\n",
    "# Add a convolutional layer with 16 filters, 3x3 kernel size, and sigmoid activation\n",
    "model_c.add(Conv2D(16, kernel_size=(3, 3), activation='sigmoid', input_shape=input_shape))\n",
    "\n",
    "# Add a max pooling layer with 2x2 pool size\n",
    "model_c.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Add a convolutional layer with 32 filters, 3x3 kernel size, and sigmoid activation\n",
    "model_c.add(Conv2D(32, kernel_size=(3, 3), activation='sigmoid'))\n",
    "\n",
    "# Add a max pooling layer with 2x2 pool size\n",
    "model_c.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the output of the previous layer\n",
    "model_c.add(Flatten())\n",
    "\n",
    "# Add a dense layer with 512 units and relu activation\n",
    "model_c.add(Dense(512, activation='relu'))\n",
    "\n",
    "# Add the output layer with 46 units and softmax activation\n",
    "model_c.add(Dense(46, activation='softmax'))\n",
    "\n",
    "# Compile the model with categorical crossentropy loss and Adam optimizer\n",
    "model_c.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model_c.summary()\n",
    "\n",
    "# Train the model on the top left quadrant dataset\n",
    "model_c.fit(x_train_c, train_labels_onehot, batch_size=32, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2444/2444 [==============================] - 4s 2ms/step\n",
      "2444/2444 [==============================] - 4s 2ms/step\n",
      "2444/2444 [==============================] - 6s 3ms/step\n",
      "2444/2444 [==============================] - 6s 3ms/step\n",
      "2444/2444 [==============================] - 6s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# create new models to extract features from the last dense layer\n",
    "model_tl_features = Model(inputs=model_tl.input, outputs=model_tl.get_layer('dense').output)\n",
    "model_tr_features = Model(inputs=model_tr.input, outputs=model_tr.get_layer('dense_2').output)\n",
    "model_bl_features = Model(inputs=model_bl.input, outputs=model_bl.get_layer('dense_4').output)\n",
    "model_br_features = Model(inputs=model_br.input, outputs=model_br.get_layer('dense_6').output)\n",
    "model_c_features = Model(inputs=model_c.input, outputs=model_c.get_layer('dense_8').output)\n",
    "\n",
    "# extract features from the last dense layer for each quadrant\n",
    "tl_features = model_tl_features.predict(x_train_tl)\n",
    "tr_features = model_tr_features.predict(x_train_tr)\n",
    "bl_features = model_bl_features.predict(x_train_bl)\n",
    "br_features = model_br_features.predict(x_train_br)\n",
    "center_features = model_c_features.predict(x_train_c)\n",
    "\n",
    "# concatenate the features from all 5 quadrants into a single input\n",
    "features = np.concatenate((tl_features, tr_features, bl_features, br_features, center_features), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2444/2444 [==============================] - 529s 216ms/step - loss: 0.3477 - accuracy: 0.9035\n",
      "Epoch 2/10\n",
      "2444/2444 [==============================] - 584s 239ms/step - loss: 0.1618 - accuracy: 0.9607\n",
      "Epoch 3/10\n",
      "2444/2444 [==============================] - 562s 230ms/step - loss: 0.1257 - accuracy: 0.9713\n",
      "Epoch 4/10\n",
      "2444/2444 [==============================] - 519s 212ms/step - loss: 0.1055 - accuracy: 0.9771\n",
      "Epoch 5/10\n",
      "2444/2444 [==============================] - 366s 150ms/step - loss: 0.0935 - accuracy: 0.9800\n",
      "Epoch 6/10\n",
      "2444/2444 [==============================] - 379s 155ms/step - loss: 0.0849 - accuracy: 0.9825\n",
      "Epoch 7/10\n",
      "2444/2444 [==============================] - 378s 154ms/step - loss: 0.0753 - accuracy: 0.9856\n",
      "Epoch 8/10\n",
      "2444/2444 [==============================] - 376s 154ms/step - loss: 0.0688 - accuracy: 0.9862\n",
      "Epoch 9/10\n",
      "2444/2444 [==============================] - 383s 157ms/step - loss: 0.0662 - accuracy: 0.9876\n",
      "Epoch 10/10\n",
      "2444/2444 [==============================] - 384s 157ms/step - loss: 0.0624 - accuracy: 0.9887\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# define the DNN classifier model\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(2560, activation='relu', input_shape=(features.shape[1],)))\n",
    "classifier.add(Dense(1000, activation='relu'))\n",
    "classifier.add(Dense(1000, activation='relu'))\n",
    "classifier.add(Dense(1000, activation='relu'))\n",
    "classifier.add(Dense(46, activation='softmax'))\n",
    "\n",
    "# compile the model\n",
    "classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = classifier.fit(features, train_labels_onehot, batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the test data for prediction and testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels_int = label_encoder.fit_transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the integer labels to one-hot encoding\n",
    "test_labels_onehot = to_categorical(test_labels_int, num_classes=46)\n",
    "\n",
    "# Split the data into the five quadrants\n",
    "x_test_tl = test_images[:,:14,:14].reshape(-1, 14, 14, 1)\n",
    "x_test_tr = test_images[:,:14,14:].reshape(-1, 14, 14, 1)\n",
    "x_test_bl = test_images[:,14:,:14].reshape(-1, 14, 14, 1)\n",
    "x_test_br = test_images[:,14:,14:].reshape(-1, 14, 14, 1)\n",
    "x_test_c = test_images[:,7:21,7:21].reshape(-1, 14, 14, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432/432 [==============================] - 1s 2ms/step\n",
      "432/432 [==============================] - 1s 2ms/step\n",
      "432/432 [==============================] - 1s 1ms/step\n",
      "432/432 [==============================] - 1s 1ms/step\n",
      "432/432 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# extract features from the last dense layer for each quadrant\n",
    "tl_features_test = model_tl_features.predict(x_test_tl)\n",
    "tr_features_test = model_tr_features.predict(x_test_tr)\n",
    "bl_features_test = model_bl_features.predict(x_test_bl)\n",
    "br_features_test = model_br_features.predict(x_test_br)\n",
    "center_features_test = model_c_features.predict(x_test_c)\n",
    "\n",
    "# concatenate the features from all 5 quadrants into a single input\n",
    "features_test = np.concatenate((tl_features_test, tr_features_test, bl_features_test, br_features_test, center_features_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432/432 [==============================] - 7s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "test_predictions = classifier.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "accuracy = accuracy_score(test_labels_int, test_predictions.argmax(axis=1))\n",
    "precision = precision_score(test_labels_int, test_predictions.argmax(axis=1), average='weighted')\n",
    "recall = recall_score(test_labels_int, test_predictions.argmax(axis=1), average='weighted')\n",
    "f1 = f1_score(test_labels_int, test_predictions.argmax(axis=1), average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9729710144927536\n",
      "Precision: 0.9733038582412864\n",
      "Recall: 0.9729710144927536\n",
      "F1 Score: 0.9729837866942165\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', accuracy)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1 Score:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
